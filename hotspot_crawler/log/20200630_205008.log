2020-06-30 20:50:08 [scrapy.utils.log] INFO: Scrapy 2.1.0 started (bot: hotspot_crawler)
2020-06-30 20:50:08 [scrapy.utils.log] INFO: Versions: lxml 4.5.1.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 22:22:21) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-06-30 20:50:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-06-30 20:50:08 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'hotspot_crawler',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': './hotspot_crawler/log/20200630_205008.log',
 'NEWSPIDER_MODULE': 'hotspot_crawler.spiders',
 'SPIDER_MODULES': ['hotspot_crawler.spiders.TencentHotspot',
                    'hotspot_crawler.spiders.SohuHotspot',
                    'hotspot_crawler.spiders.XinhuaHotspot',
                    'hotspot_crawler.spiders.HuanqiuHotspot',
                    'hotspot_crawler.spiders.BaiduHotspot',
                    'hotspot_crawler.spiders.FengHuangHotspot',
                    'hotspot_crawler.spiders.SinaHotspot']}
2020-06-30 20:50:08 [scrapy.extensions.telnet] INFO: Telnet Password: 63aae0811aa50a26
2020-06-30 20:50:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2020-06-30 20:50:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'hotspot_crawler.middlewares.HotspotCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'hotspot_crawler.middlewares.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-06-30 20:50:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'hotspot_crawler.middlewares.HotspotCrawlerSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-06-30 20:50:09 [scrapy.middleware] INFO: Enabled item pipelines:
['hotspot_crawler.pipelines.JSONWithEncodingPipeline']
2020-06-30 20:50:09 [scrapy.core.engine] INFO: Spider opened
2020-06-30 20:50:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-06-30 20:50:09 [HuanqiuHotspot] INFO: Spider opened: HuanqiuHotspot
2020-06-30 20:50:09 [HuanqiuHotspot] INFO: Spider opened: HuanqiuHotspot
2020-06-30 20:50:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-06-30 20:50:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://3w.huanqiu.com/> (referer: None)
2020-06-30 20:50:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.huanqiu.com/> from <GET http://www.huanqiu.com/>
2020-06-30 20:50:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.huanqiu.com/> (referer: None)
2020-06-30 20:50:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://china.huanqiu.com/article/2019-09/15426661.html> from <GET http://china.huanqiu.com/article/2019-09/15426661.html>
2020-06-30 20:50:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://china.huanqiu.com/article/9CaKrnKmJ6J> from <GET https://china.huanqiu.com/article/2019-09/15426661.html>
2020-06-30 20:50:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://china.huanqiu.com/article/9CaKrnKmJ6J> (referer: None)
2020-06-30 20:50:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://china.huanqiu.com/article/9CaKrnKmJ6J>
{'content': '（新闻联播）：2014年，习近平总书记两次来到河南兰考。总书记叮嘱兰考的党员干部，要“切实关心农村每个家庭特别是贫困家庭，通过因地制宜发展产业促进农民增收致富。”落实总书记重要要求，兰考作出了“三年脱贫、七年小康”的承诺，几年来，当地因地制宜，发展壮大产业，顺利脱贫摘帽。别看现在的闫春光春风满面，在5年前，他还是村里的贫困户。那一年，他养的1000只鸡遇上了禽流感，赔了几万块钱，鸡场还差点关了门。也是在那一年，2014年3月，习近平总书记到张庄村看望贫困百姓，来到了闫春光家。闫春光告诉总书记，他养鸡赔了钱，正在为今后的生活犯愁，总书记鼓励他坚持下去，日子一定会好起来。那时候的兰考像张庄这样的贫困村，共有115个，像闫春光这样建档立卡的贫困人口有7.7万人，脱贫是最难啃的硬骨头。落实总书记要求，脱贫攻坚在兰考全面打响。当年，兰考就把345名干部派驻到115个贫困村，不拔穷根不撤队伍。金融支持、风险补偿等一项项措施相继出台。闫春光成了新政策的受益人。很快，他领到10万元的扶持资金，县里的科技服务团也为他送来了技术，春光养鸡场重新开张。几年来，养鸡规模从3000只扩大到10000只，闫春光走上了致富路。几年来，兰考先后培育特色专业村28个，发展农民专业合作社1520家，家庭农场167家。这个国家级贫困县也开始走上了脱贫路，2017年3月27日，兰考率先在全国脱贫摘帽。如今的兰考县，正在因地制宜，打造木材加工、特色农产品畜牧养殖和战略新兴产业等三大主导产业。',
 'publish_time': '2019.09.09 08:24:00',
 'title': '【壮丽70年奋斗新时代——重温嘱托看变化】河南兰考：小康路上打造发展新名片',
 'url': 'https://china.huanqiu.com/article/9CaKrnKmJ6J'}
2020-06-30 20:50:27 [scrapy.core.engine] INFO: Closing spider (finished)
2020-06-30 20:50:27 [scrapy.core.engine] ERROR: Scraper close failure
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\pipelines.py", line 35, in close_spider
    MysqlOperation.dis_connect()
TypeError: dis_connect() missing 1 required positional argument: 'self'
2020-06-30 20:50:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1396,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 46855,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 3,
 'downloader/response_status_count/301': 3,
 'elapsed_time_seconds': 18.620453,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 6, 30, 12, 50, 27, 990668),
 'item_scraped_count': 1,
 'log_count/DEBUG': 7,
 'log_count/ERROR': 1,
 'log_count/INFO': 12,
 'request_depth_max': 1,
 'response_received_count': 3,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2020, 6, 30, 12, 50, 9, 370215)}
2020-06-30 20:50:27 [scrapy.core.engine] INFO: Spider closed (finished)

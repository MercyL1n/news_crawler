2020-06-30 19:58:27 [scrapy.utils.log] INFO: Scrapy 2.1.0 started (bot: hotspot_crawler)
2020-06-30 19:58:27 [scrapy.utils.log] INFO: Versions: lxml 4.5.1.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 22:22:21) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1g  21 Apr 2020), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2020-06-30 19:58:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-06-30 19:58:27 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'hotspot_crawler',
 'CONCURRENT_REQUESTS': 32,
 'COOKIES_ENABLED': False,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': './hotspot_crawler/log/20200630_195826.log',
 'NEWSPIDER_MODULE': 'hotspot_crawler.spiders',
 'SPIDER_MODULES': ['hotspot_crawler.spiders.TencentHotspot',
                    'hotspot_crawler.spiders.SohuHotspot',
                    'hotspot_crawler.spiders.XinhuaHotspot',
                    'hotspot_crawler.spiders.HuanqiuHotspot',
                    'hotspot_crawler.spiders.BaiduHotspot',
                    'hotspot_crawler.spiders.FengHuangHotspot',
                    'hotspot_crawler.spiders.SinaHotspot']}
2020-06-30 19:58:27 [scrapy.extensions.telnet] INFO: Telnet Password: c6c54913af6a72ed
2020-06-30 19:58:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2020-06-30 19:58:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'hotspot_crawler.middlewares.HotspotCrawlerDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'hotspot_crawler.middlewares.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-06-30 19:58:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'hotspot_crawler.middlewares.HotspotCrawlerSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-06-30 19:58:27 [scrapy.middleware] INFO: Enabled item pipelines:
['hotspot_crawler.pipelines.JSONWithEncodingPipeline']
2020-06-30 19:58:27 [scrapy.core.engine] INFO: Spider opened
2020-06-30 19:58:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-06-30 19:58:27 [BaiduHotspot] INFO: Spider opened: BaiduHotspot
2020-06-30 19:58:27 [BaiduHotspot] INFO: Spider opened: BaiduHotspot
2020-06-30 19:58:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-06-30 19:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://news.baidu.com/> (referer: None)
2020-06-30 19:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670914908167595360> (referer: http://news.baidu.com/)
2020-06-30 19:58:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670914908167595360>
{'content': '病例1，男，61岁，住址为丰台区新村街道银地家园，新发地市场个体经营人员。6月13日由专车转运至集中隔离点进行集中医学观察。6月26日核酸检测结果为阳性。6月27日由120救护车转运至丰台中西医结合医院就诊，6月28日诊断为疑似病例，由120救护车转运至地坛医院，核酸检测结果为阳性，6月29日确诊，临床分型为普通型。病例2，男，49岁，住址为丰台区花乡(地区)经营者乐园，新发地市场个体经营人员。6月13日由专车转运至集中隔离点进行集中医学观察。6月26日核酸检测结果为阳性。6月27日由120救护车转运至丰台中西医结合医院就诊，6月28日诊断为疑似病例，由120救护车转运至地坛医院，核酸检测结果为阳性，6月29日确诊，临床分型为普通型。病例3，男，51岁，住址为丰台区花乡(地区)天骄俊园，新发地市场个体经营人员。6月13日由专车转运至集中隔离点进行集中医学观察，6月26日出现咳嗽、胸闷、胸痛等症状，6月27日由120救护车转运至丰台区南苑医院就诊，核酸检测结果为阳性，6月28日由120救护车转运至地坛医院，6月29日确诊，临床分型为普通型。病例4，男，64岁，住址为丰台区花乡(地区)乡新发地电商产业园南苑西路346号平房，新发地市场保洁员。6月13日由专车转运至集中隔离点进行集中医学观察，6月27日核酸检测结果为阳性，6月28日由120救护车转运至丰台中西医结合医院就诊，6月29日确诊，临床分型为普通型。病例5，男，63岁，住址为丰台区花乡(地区)乡新发地电商产业园南苑西路346号平房，新发地市场保洁员。6月13日由专车转运至集中隔离点进行集中医学观察，6月20日出现咳嗽等症状，未报告、未服药，6月27日核酸检测结果为阳性，6月28日由120救护车转运至丰台中西医结合医院就诊，6月29日确诊，临床分型为普通型。病例6，男，27岁，住址为丰台区花乡(地区)巴庄子，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察。6月26日出现发热、乏力等症状，6月27日由120救护车转运至丰台中西医结合医院就诊。当日由120救护车转运至地坛医院就诊，6月29日核酸检测结果为阳性，当日确诊，临床分型为普通型。病例7，女，70岁，住址为大兴区西红门(地区)镇星光巷7号保利达公寓，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察。6月27日出现发热等症状，由120救护车转运至丰台中西医结合医院就诊。6月28日由120救护车转运至地坛医院就诊，核酸检测结果为阳性，6月29日确诊，临床分型为普通型。病例1，女，31岁，住址为丰台区花乡(地区)经营者乐园，新发地市场个体经营人员。6月13日由专车转运至集中隔离点进行集中医学观察。6月26日核酸检测结果为阳性，6月27日由120救护车转运至丰台中西医结合医院就诊。6月28日确诊，临床分型为轻型。病例2，女，42岁，住址为丰台区花乡(地区)新发地国际名酒城，新发地市场个体经营人员。6月19日被确定为确诊病例的密切接触者，由专车转运至集中隔离点进行集中医学观察;6月27日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊。6月28日确诊，临床分型为普通型。病例3，女，25岁，住址为丰台区花乡(地区)新发地市场，近1年在大兴区黄村做家教，父母为新发地市场个体经营人员，平时与父母同住，6月14日由专车转运至集中隔离点进行集中医学观察。6月16日被确定为确诊病例的密切接触者。6月26日核酸检测结果为阳性，6月27日由120救护车转运至昌平区医院就诊，6月28日确诊，临床分型为普通型。病例4，男，37岁，住址为丰台区丰台街道东大街，保安。6月16日被确定为确诊病例的密切接触者，由专车转运至集中隔离点进行集中医学观察;6月26日核酸检测结果为阳性，6月27日出现发热等症状，当日由120救护车转运至丰台中西医结合医院就诊。6月28日确诊，临床分型为普通型。病例5，女，56岁，住址为丰台区新村街道银地家园，新发地市场个体经营人员。6月13日由专车转运至集中隔离点进行集中医学观察，6月26日核酸检测结果为阳性。6月27日由120救护车转运至丰台中西医结合医院就诊，6月28日确诊，临床分型为普通型。病例2，男，43岁，住址为丰台区花乡(地区)宜兰园，新发地市场个体经营人员。6月13日由专车转运至集中隔离点进行集中医学观察，6月26日出现发热症状，核酸检测结果为阳性。6月27日由120救护车转运至丰台中西医结合医院就诊，当日确诊，临床分型为普通型。病例1，女，31岁，住址为丰台区花乡(地区)天骄俊园，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察。6月26日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊，6月27日确诊，临床分型为普通型。病例2，男，47岁，住址为丰台区花乡(地区)经营者乐园，新发地市场个体经营人员。6月13日由专车转运至集中隔离点进行集中医学观察，6月26日出现咽痛等症状，核酸检测结果为阳性。6月27日由120救护车转运至丰台中西医结合医院就诊，当日确诊，临床分型为普通型。病例3，女，63岁，住址为丰台区花乡(地区)宜兰园，新发地市场保洁员。6月12日晚由专车转运至集中隔离点进行集中医学观察，6月27日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊，当日确诊，临床分型为普通型。病例4，女，53岁，住址为丰台区卢沟桥(地区)大屯村，新发地北水嘉伦市场便民超市A厅老郑州烩面馆员工。6月21日被确定为确诊病例的密切接触者，当日出现头痛、胸闷等症状。6月22日由专车转运至集中隔离点进行集中医学观察。6月23日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊。6月25日由120救护车转运至地坛医院，6月27日确诊，临床分型为轻型。病例5，男，49岁，住址为丰台区花乡(地区)天骄俊园，新发地市场个体经营人员。6月13日由专车转运至集中隔离点进行集中医学观察，6月26日出现症状,6月27日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊，当日确诊，临床分型为普通型。病例6，女，52岁，住址为丰台区花乡(地区)天伦锦城，新发地市场个体经营人员，6月16日由专车转运至集中隔离点进行集中医学观察，6月24日出现胸闷等症状，体温正常，6月27日核酸检测结果为阳性，由120救护车转至丰台中西医结合医院就诊，当日确诊，临床分型为普通型。病例8，女，43岁，住址为丰台区花乡(地区)天伦锦城，新发地市场个体经营人员。6月10日开始出现乏力、发热、咳嗽等症状，自行到诊所就诊并服药、输液治疗，体温恢复正常，但有咽痒等症状。6月13日至16日居家未外出。6月16日由专车转运至集中隔离点进行集中医学观察。6月26日核酸检测结果为阳性。6月27日由120救护车转运至丰台中西医结合医院就诊，当日确诊，临床分型为普通型。病例9，男，42岁，住址为大兴区高米店街道兴华大街二段，新发地市场个体经营者。6月12日由专车转运至集中隔离点进行集中医学观察，6月26日核酸检测结果为阳性。6月27日由120救护车转运至丰台中西医结合医院就诊，当日确诊，临床分型为普通型。病例10，女，39岁，住址为大兴区魏善庄镇北京密码，海淀区定慧谢小厨餐厅服务员。6月24日被判定为确诊病例的密切接触者，由专车转运至集中隔离点进行集中医学观察。6月25日出现全身酸痛等症状。6月26日由120救护车转运至大兴区人民医院就诊，核酸检测结果为阳性，6月27日确诊，临床分型为轻型。病例12，女，25岁，住址为大兴区西红门(地区)寿保庄村，北京大通远鑫汽车修理有限公司车险销售员，在北京车谷汽车销售有限公司办公。6月20日至23日上班或在家休息，曾在村内超市购物。6月24日出现流涕等症状，未服药、未就医。6月26日被确定为确诊病例的密切接触者，由专车转运至集中隔离点进行集中医学观察;当日核酸检测结果为阳性，由120救护车转运至大兴区人民医院就诊。6月27日确诊，临床分型为普通型。病例1，女，38岁，住址为丰台区花乡(地区)天伦锦城，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊，6月26日确诊，临床分型为普通型。病例2，男，51岁，住址为丰台区花乡(地区)经营者乐园，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院，26日确诊，临床分型为普通型。病例3，女，51岁，住址为丰台区花乡(地区)经营者乐园，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院，26日确诊，临床分型为普通型。病例4，女，49岁，住址为丰台区花乡(地区)天伦锦城，新发地市场个体经营人员，6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车送至丰台中西医结合医院，26日确诊，临床分型为普通型。病例5，女，46岁，住址为丰台区花乡(地区)新发地商户乐园，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊，26日确诊，临床分型为普通型。病例6，男，43岁，住址为丰台区花乡(地区)天伦锦城，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车送至丰台中西医结合医院，26日确诊，临床分型为普通型。病例7，男，29岁，住址为丰台区花乡(地区)经营者乐园，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院，26日确诊。临床分型为普通型。病例8，女，55岁，住址为丰台区花乡(地区)宜兰园，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车送至丰台中西医结合医院，26日确诊，临床分型为普通型。病例9，男，30岁，住址为丰台区花乡(地区)经营者乐园，新发地市场销售人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊，26日确诊，临床分型为普通型。病例10，男，27岁，住址为丰台区花乡(地区)天骄俊园，新发地市场个体经营人员，6月12日由专车转运至集中隔离点进行集中医学观察，6月24日出现咽部不适，核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院，26日确诊，临床分型为普通型。病例11，男，23岁，住址为丰台区花乡(地区)天伦锦城，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察。6月24日核酸检测结果为阳性，陆续出现发热、咽干、咳嗽等症状，由120救护车转运至丰台中西医结合医院就诊。26日确诊，临床分型为普通型。病例12，男，29岁，住址为丰台区花乡(地区)宜兰园，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊，26日确诊，临床分型为普通型。病例13，女，55岁，住址为丰台区花乡(地区)经营者乐园，新发地市场个体经营人员。6月12日由专车转运至集中隔离点进行集中医学观察，6月24日核酸检测结果为阳性，由120救护车转运至丰台中西医结合医院就诊，26日确诊，临床分型为普通型。病例14，男，50岁，住址为丰台区新村街道银地家园，新发地市场个体经营人员。6月15日由专车转运至集中隔离点进行集中医学观察。6月22日核酸检测结果为阴性，新冠病毒IgM抗体阳性，由120救护车转运至丰台中西医结合医院就诊，26日核酸检测结果为阳性，当日确诊，临床分型为普通型。编辑常江',
 'publish_time': '2020-06-30 17:16:00',
 'title': '北京近4日37例确诊病例发现于集中隔离点',
 'url': 'http://baijiahao.baidu.com/s?id=1670914908167595360'}
2020-06-30 19:58:28 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://baijiahao.baidu.com/s?id=1670914908167595360> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-06-30 19:58:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9552617443588981990%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
2020-06-30 19:58:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9552617443588981990%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670852409110574829> (referer: http://news.baidu.com/)
2020-06-30 19:58:33 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670852409110574829>
{'content': '近日，"蚂蚁矿机ANTMINER"在微博发布北京比特大陆科技有限公司（以下简称"北京比特大陆"）关于近期经营协作的磋商及实时进展公告，称两位大股东——即詹克团与吴忌寒已就目前公司的生产经营问题达成了共识。但令外界错愕的是，该公告很快被删除。自2019年10月以来，比特大陆科技控股公司（于开曼群岛注册成立以不同投票权控制的有限公司，下称“比特大陆”）两大股东吴忌寒和詹克团争斗就从未停过，双方数次通过各种渠道发布公告，就公司法人、公章、公众号归属等问题争执不下，甚至还在今年5月上演了"当当式"抢夺营业执照戏码。而在比特大陆股东内斗不断的同时，竞争对手嘉楠耘智和亿邦国际已经成功在美股上市。有业内人士向雷达财经表示，如果比特大陆大股东内斗迟迟不解决，不排除被竞争对手超越。公开资料显示，吴忌寒毕业于北京大学经济学院，主要负责比特大陆市场业务，而来自中国科学院微电子研究所的詹克团则被看作比特大陆"技术大脑"。在二人的努力下，比特大陆发展迅速。2018年比特大陆向香港联交所递交的招股书显示，按2017年收入计，这家公司就已经是中国第二大、全球前十大无晶圆厂芯片设计公司、全球第四大无晶圆厂ASIC芯片设计公司。而根据Frost&Sullivan数据,以2017年收入计算,比特大陆是全球最大的基于ASIC的加密货币矿机公司,占有全球74.5%的市场份额。2017年和2018年上半年，比特大陆的营收分别为25.17亿美元、28.45亿美元，净利润分别为7.01亿美元、7.42亿美元，调整后净利润（不包括股权激励费用及可换股可赎回优先股的公允价值变动）均为9.52亿美元。但毛利率却从2016年顶峰的54.5%下降至2018年前6个月的36.2%。自成立以来，比特大陆共完成三轮融资：2017年8月A轮融资5000万美元，2018年6月B轮融资2.9亿美元，2018年8月B+轮融资4.4亿美元。参投方包括IDG资本、红杉资本、美国对冲基金CoatueManagement、新加坡政府投资基金EDBI等。然而业绩辉煌的背后，两位创始人出现裂痕。据媒体报道，吴忌寒和詹克团在公司发展方面的看法不尽相同。吴忌寒想继续扩大比特大陆在数字货币领域的份额，同时在国际化道路上努力，而詹克团则希望将比特大陆转型为人工智能方向。据21世纪经济报道，2018年正逢比特币大跌，吴忌寒的比特币现金计划亏损了30多亿人民币的资产，他也因此在年底卸任自己在比特大陆的所有职务并退出核心决策层。但吴忌寒很快卷土重来。2019年10月29日，吴忌寒发布内部信，解除詹克团在北京比特大陆的一切职务。内部信要求，比特大陆任何员工不得再执行詹克团的指令，不得参加詹克团召集的会议，如有违反，公司将视情节轻重考虑解除劳动合同，这被外界看作比特大陆内斗正式爆发的起点。当时，詹克团正在深圳参展2019年深圳安博会。等他回到比特大陆时，却发现自己已被禁止进入公司的办公区域。从股权结构看，当时詹克团更占优势。当时，詹克团持股36%，吴忌寒持股20.25%，而由于开曼公司实行AB股，詹吴两人手中所持的B股均有10倍投票权，詹克团占据59.6%的投票权。不过，比特大陆在去年11月举行的股东大会上就取消了詹克团的10倍投票权，改为1股1票，这使詹克团丧失了投票优势。詹克团随即聘请汉坤律师事务所，向北京市海淀区人民法院提起行政诉讼，对北京市海淀区市场监督管理局作出的工商变更登记表示异议，与此同时还发起第一次行政复议，请求撤销比特大陆变更法定代表人和执行董事的行为。据彭博社报道，詹克团在2019年12月还曾提交传票，要求开曼群岛法院撤销股东大会上取消AB股的决定，但这一国际诉讼至今尚未做出最终判决。2020年1月31日，北京市海淀区司法局同意了詹克团的撤销申请，但早在1月2日，比特大陆就再次将法人由吴忌寒换为公司首席财务官刘路遥，这一布局使得詹克团夺回法定代表人身份的想法落空。今年2月12日，詹克团提起第二次行政复议，请求撤销海淀区市场监管局批准的1月2日法人变更登记行为，并将比特大陆法人恢复为自身。今年4月28日，北京市海淀区司法局正式撤销刘路遥法定代表人身份，北京比特大陆在市场监管部门登记的状态恢复至2019年10月28日之前。对此，吴忌寒一方认为，因为北京比特大陆由香港的BitmainTechnologiesLimited（下称“香港比特大陆”）100%控股，而注册于开曼群岛的BitMainTechnologiesHoldingCompany（比特大陆）100%持股香港比特大陆，因此北京地区比特大陆的法人任免本应由开曼、香港股东决定，而非行政机关。4月27日和4月29日，微信公众号"比特大陆科技"连续发布两则声明，称詹克团无视公司及全体员工的共同利益，在疫情特殊时期恶意提起诉讼，干扰公司的正常运营，破坏国家保稳定、保增长的方针。并已对詹克团可能采取的5项破坏活动做好充分准备，严阵以待。5月28日，一场“大戏”上演。当日上午，詹克团在海淀区政务服务中心二楼52号窗口领取自己为法定代表人的北京比特大陆公司营业执照时，营业执照被一群不明身份的大汉从工商行政人员手中抢走，其中刘路遥在现场指挥了这次有计划的"抢劫"。就在刘路遥率人"抢执照"的当天，香港比特大陆微博发表声明文章，称"詹克团已不在\'北京比特\'担任任何职务，也未经本公司授权，无权领取本公司营业执照。市场监管部门公示登记显示詹克团为我司法定代表人属于登记错误，且严重违反《公司法》的规定。公司唯一合法的法定代表人为总经理刘路遥。"虽然詹克团营业执照被抢走，但在国家企业信用信息公示系统中，詹克团已是北京比特大陆法定代表人。至此，北京比特大陆在9个月内，已三次更换法定代表人。重新担任法定代表人后，詹克团开始了“清算”之旅。5月25日，詹克团以北京比特大陆法定代表人的身份签发了对刘路遥的"解除劳动关系通知"。在解除文件中，刘路遥被指存在严重违反公司规章制度的行为，包括但不限于5月8日在海淀区市场监督管理局依法向公司法人詹克团发放营业执照过程中，组织、策划并参与抢夺营业执照。5月27日下午，北京比特大陆发布声明称，公司已于2019年10月28日通过股东决定免去詹克团的公司执行董事、法定代表人职务，且于2019年11月5日通过执行董事决定免去詹克团经理职务。鉴于此，詹克团无权以公司法定代表人、执行董事或经理的名义从事任何行为。解除刘路遥劳动合同失效后，詹克团很快又将注意力转移到了公章上。6月10日，詹克团一方通过微信公众号"比特大陆科技"发布"关于启用新公章并作废旧公章的声明"，表示旧公章于5月8日起失效，新公章于6月1日起生效。一天之后，比特大陆官网发布声明称，北京比特大陆和香港比特大陆发现微信公众号"比特大陆科技"于2020年6月10日登陆状态异常，并宣布当日发布的信息内容虚假，不代表北京比特大陆真实意志。目前唯一合法有效的公章是编号为1101070056574的公章。6月13日，比特大陆官网发布北京比特大陆和香港比特大陆联合声明书，再次强调2019年10月免职詹克团行为的真实性，并列举了詹克团行为：包括非法取得所谓北京比特大陆印章证照、假借北京比特大陆名义行事、与其持股的海南大陆方舟数据科技有限公司签署《销售代理协议》等。声明中重申：加盖詹克团以非法手段取得的所谓北京比特公章（编号1101081651178）的任何文件，北京比特大陆与香港比特大陆均不予认可。北京比特公章（编号1101070056574）由吴忌寒授权人员保管，正常使用。一周后，詹克团在微博上给予回应，坚持原公章（编号为1101070056574）已作废，自己手中的新公章（编号为1101081651178）系比特大陆唯一合法有效的公章。比特大陆官网随即发布第三封公告，称比特大陆充分支持吴忌寒，并称香港比特大陆已经暂时停止了向詹克团亲属所控制的世纪云芯的芯片供给。6月21日，一份比特大陆员工发布的"对吴忌寒不合法、不守法、不懂法行为的说明"的声明流出。声明称"吴忌寒所有的行为都是建立在不合法基础上的非法行为，正在将比特大陆和一部分员工拖入深渊"。除此之外，声明中还提到："在詹克团重获比特大陆控制权后，吴忌寒采取了如抢执照、转移公司文件和资产、冒用公司名义造谣等严重违法的疯狂行为。詹克团正在以40亿美元估值收购吴忌寒及其他老股东和部分员工的股份，并将以法律手段解决此问题。"对此，比特大陆官网于6月23日再发公告，重申2019年11月股东大会废除十倍投票权的决议合法有效。公告称，行政机关无权否决该等决定中有关北京比特管理者任免的内容，无论公司登记信息目前状态如何，都不改变詹克团先生已不在北京比特任职、无权代表北京比特行事之事实。公告强调，北京比特的公章一直处于妥善保管、合法使用状态，公司并未申请挂失、重刻公章。同样在6月23日，吴忌寒控制下的微信公众号“蚂蚁矿机ANTMINER”发布了关于北京比特大陆经营协作的磋商及实施进展公告，表示本着为比特大陆负责的原则，两位大股东派出代表，在热心股东和热心第三方的帮助下，就公司生产经营等基本问题进行了磋商，并初步达成了共识。主要共识包括：第一，尽可能维持公司正常生产经营秩序，特别是降低对外部客户和供应商的影响；第二，保持公司账务及时和完整，确保公司财税合规；第三，稳定公司员工。然而，蚂蚁矿机发布的声明很快被删除，这让外界颇为错愕。陷于内斗的比特虽然早在2018年9月，即向港交所递交招股书，然而直至今日，比特大陆依然未能登陆资本市场。而比特大陆的竞争对手嘉楠耕智已经在2019年年底成功赴美上市，而亿邦国际在今年6月26日已成功在美股上市。据亿邦国际6月17日递交的最新版招股书显示，该公司拟发行1932.36万股，发行价区间为4.5美元到6.5美元，拟募资金额为8695万美元到1.25亿美元，若承销商行使选择权全额购买额外的A类普通股，则最高发行总量达2222.214万股，由此计算，最高可募资1.44亿美元。与此同时，亿邦国际的新招股书中公布了其2020年第一季度未经审计的财务报告。报告显示，截至2020年3月31日，亿邦国际第一季度营收为640万美元，同比增长6.1%；营收成本590万美元，同比下降3.9%。另外，亿邦国际净亏损在进一步扩大，已从2019年第一季度净亏损60万美元，扩大至2020年一季度的250万美元。对此，亿邦国际解释，净亏损扩大主要原因为地方政府退税大幅减少，此外，亿邦国际收入主要集中在比特币采矿机上，比特币价格的大幅下跌将对公司比特币采矿机库存的价值产生负面影响。6月26日，亿邦国际正式登陆纳斯达克，发行价格为5.23美元，首日开盘后迅速破发至4.60美元，并一路走低，最低触及3.81美元，相较发行价暴跌27.15%，随后股价上涨，最终收盘价格为5美元。有区块链从业人士向雷达财经表示，嘉楠耘智和亿邦国际上市后，可以获得资本输血。虽然比特大陆相比竞争对手，盈利能力更强，技术更好，但如果股东一直处于内斗状态，不安心做好经营，存在被竞争对手超越的风险。注：本文是雷达财经（ID：leidacj）原创。未经授权，禁止转载。',
 'publish_time': '2020-06-30 00:43:00',
 'title': '比特大陆版“权力的游戏”：免职、抢营业执照、和解共识被删',
 'url': 'http://baijiahao.baidu.com/s?id=1670852409110574829'}
2020-06-30 19:58:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9901138096902809825%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
2020-06-30 19:58:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9901138096902809825%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670890939763251893> (referer: http://news.baidu.com/)
2020-06-30 19:58:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670890939763251893>
{'content': '【TechWeb】6月30日消息，据国外媒体报道，自从特斯拉的弗里蒙特工厂恢复正常运营以来，该公司一直努力在第二季度尽可能取得成功。当地时间周一，电动汽车制造商特斯拉的首席执行官（CEO）埃隆·马斯克（ElonMusk）在一封内部电子邮件中呼吁员工努力工作，帮助该公司在第二季度新冠疫情期间实现收支平衡。与此同时，瑞信对特斯拉2020年第二季度的交付和生产数据进行了预测。瑞信分析师丹·利维（DanLevy）在一份给投资者的报告中表示，特斯拉第二季度的交付量可能在9万至10万辆之间，而卖方的普遍预期是7万辆，买方的普遍预期可能是8万辆。他预计，在特斯拉第二季度的交付量中，约有3.1万辆来自该公司的上海工厂，不到3.5万辆来自其弗里蒙特工厂，约有2.5万辆来自全球库存。此外，他还预计，特斯拉第二季度的产量约为7.6万至8.8万辆。他表示，与几周前相比，该公司实现季度盈利并不是一个激进的想法。此前，由于受疫情影响，特斯拉的弗里蒙特工厂从3月24日开始临时停产。在关闭了一个多月后，该工厂于5月18日重新开业。不过，在该工厂再次开放并重新生产电动汽车之后，其产能要达到3月24日停产之前的水平还需要一段时间。当地时间周一，马斯克呼吁员工在第二季度末迅速生产和交付汽车，以实现特斯拉的具体目标。截至当地时间周一美股收盘，特斯拉股价上涨5.17%，报收于1009.35美元。如果按照收盘价计算，该公司的中市值为1872.10亿美元。（小狐狸）',
 'publish_time': '2020-06-30 10:56:00',
 'title': '马斯克呼吁员工努力工作帮助特斯拉在Q2实现收支平衡',
 'url': 'http://baijiahao.baidu.com/s?id=1670890939763251893'}
2020-06-30 19:58:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9921124061362408422%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
2020-06-30 19:58:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9921124061362408422%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670900922521341165> (referer: http://news.baidu.com/)
2020-06-30 19:58:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670900922521341165>
{'content': '人类的征途，是星辰大海。北京时间5月31日3时22分，一个全球瞩目的时刻。两名美国宇航员，乘坐SpaceX载人“龙飞船”，在“猎鹰9号”火箭助推下离开地球。7小时后，“龙飞船”与国际空间站对接，航天员成功进入空间站内。对SpaceX创始人马斯克来说，自己距离“移民火星计划”，又近了一步。马斯克已然封“神”。更多跟随者则跃跃欲试，将商业航天推向更大的潮头。2008年12月底，特斯拉的首席财务官告诉马斯克：彼时，马斯克已经把所有钱投进了特斯拉和SpaceX，但这两家公司都濒临破产。2006-2008年间，“猎鹰一号”三次发射，全部失败。2008年，又正值金融风暴来袭，马斯克的“火星梦”，似乎就要成为异想天开的笑话。在距离破产仅两天的时间，马斯克紧急卖掉了房子、私人飞机和麦克拉伦F1跑车。搬进空荡的酒店，他恍如隔世。“我差点被打垮了，那真是一段非常非常黑暗的日子。”2008年圣诞节前，马斯克感到世界一片黑暗。最绝望的时候，马斯克给所有的亲朋好友发邮件，希望大家能多多少少能投资一点，支持自己的事业。最终，Google创始人、eBayCEO等大佬慷慨解囊。2008年9月28日，“猎鹰一号”终于成功发射，SpaceX成为世界上第一个将火箭发射入轨的私营航天公司。这次成功，拯救了SpaceX，也拯救了马斯克。NASA（美国国家航空航天局）看到了SpaceX的潜力，很快就与它签订了商业合同。大笔一划，16亿美元。无所不能的NASA，怎么会选择与民营企业合作？第一，太贵。最早NASA用航天飞机，每次飞行费用超过10亿美元，即使载满6人，每人每次的平均发射费用也高达1.67亿美元。2011年“亚特兰蒂斯号”航天飞机完成最后一次发射任务后，所有航天飞机都退役了。第二，还是太贵。自家航天飞机太贵，NASA开始租用俄罗斯“联盟号”宇宙飞船，但报价还是一路飙升，从一开始每人每次2000多万美元的“船票”，涨到了如今的8000万美元。过去几年，NASA光“船票”就花了30多亿美元。特朗普上台后，NASA的预算开始朝不保夕。2018年预算中，地球科学分支被削减13%，教育办公室预算被全部删减。2020年，为了保住深空探索项目，NASA只得忍痛将“空间发射系统”预算，从21.5亿美元砍到17.754亿美元。于是，应了那句话，个人的努力固然重要，但也要考虑历史的进程。商业航天，由此迎来了黄金时代。值得一提的是，就在载人“龙飞船”成功升空数天后，SpaceX“星链”计划的第八次发射，再次成功将60颗卫星送入轨道。所谓就是拟在太空搭建一个由1.2万颗卫星组成的网络，形成一个低成本、高覆盖的天基全球通讯系统。不仅可为商业通信提供便利，也能向军方和科研机构提供卫星服务。一直以来，这个项目都被认为不是一个纯粹的商业计划。空天资源的争夺一直是大国角力的战场，脱胎于商业航天的“星链”所具有的军事潜力和价值，只会让国家之间的“空天之战”愈演愈烈。长久以来，航天事业都是大国高精尖技术的巅峰。但事实证明，马斯克的成功秘密是什么？商业航天与国家任务不同，成本是决胜的关键因素之一。以“万无一失”为首要目标的国家队，虽然掌握着最尖端的技术、材料、人员、装备，能最大程度确保安全可靠，但也意味着成本呈几何倍数的增加。但民营企业，会选用成熟的“工业级”部件替代尖端的“宇航级”部件。这种“偷工减料”的做法，虽然具有极大风险，但确实大大减少了成本，增大了盈利空间。以SpaceX为例，火箭制造的材料成本，还不到制造成本的3%，大部分钱花在了流水线上，极大地降低了生产成本。同时，SpaceX也深知“贪多嚼不烂”，在火箭研发上，在一段时期内就死磕一个种类，然后不断提升设计、改进工艺，大大减少了隐形研发成本。1970-2000年间，太空发射成本大约是18500美元/公斤；美国航天飞机的成本，约为54500美元/公斤；而SpaceX“猎鹰9号”，把成本打到了2720美元/公斤，只有航天飞机的1/20。此外，俄罗斯“联盟号”只能坐3人，而SpaceX“龙飞船”一次坐7人，单人单次发射成本降到了5500万美元。▲2018年发射报价对比，图/BloombergSpaceX的另一个“杀手锏”，就是回收技术。当年，马斯克说要研发回收式火箭时，全世界一片嘘声。结果2019年，SpaceX拿出了回收火箭复用成功率100%的成绩单。目前，SpaceX“龙飞船”、“猎鹰9号”火箭，理论上可实现近100次回收，即便不大修保养，也能连续回收10次。航天是一个复杂的系统工程，国家庞大的研发机构，拥有超强的研发资源和实力，民营企业在各方面都难以望其项背。但强大的资源，意味着强大的干预力量。相对于任务重大、响应缓慢的国家机构，民营企业具有决策灵活、响应迅速的天然优势。比如在火箭发动机研制过程中，NASA这样的国家机构，要经历漫长的流程申报、反复测试，耗费时间、资金巨大。而民营企业仅需要团队集中研究，便可快速决策。用互联网迭代开发的思路搞火箭，SpaceX的进步速度快得难以置信：从“蚱蜢”火箭测试返场飞行，到“猎鹰9号”火箭首次软着陆成功，只用了2年；从5吨GEO（地球静止轨道）火箭到20吨GEO火箭的改良优化，只花费了3年；Merlin发动机从玩具一样到超强推重比，只用了5年；从“龙飞船”从载货到载人，只用了3年……▲马斯克背后的硬核队友——火箭引擎工程师汤姆·穆勒人才、资金、资源，NASA不但有，甚至更多。但最后为什么SpaceX把大幅降低发射成本这件事干成了？相较于NASA的“学究风”、“科研范”，SpaceX更加“接地气”。相比“先拿钱，后干活”的国家队，民营企业不但要向资本展现技术能力，更要向投资人勾画商业航天的市场蓝图。一次访谈中，马斯克曾被问道，是如何说服NASA和美国政府，允许SpaceX做火箭生意的？他回答：“说服别人最主要的不是去游说，而是你将这件事情做到一个临界点，让大家能看到希望。”SpaceX深谙此道，展示出亮眼的“黑科技”和巨大的市场潜力。从公开的订单和投资来看，SpaceX运送美国宇航员和物资供给的合同，价值42亿美元；还收到来自17个国家共64个卫星发射订单；以及从今年开始，允许游客访问国际空间站，每人可收约5800万美元的“船票”。因此，过不了多久，世界各地的私人订单也会朝SpaceX纷沓而至。基于此，学会自我造血，才能拥有持续旺盛的生命力。这样的故事，曾在航空、通讯、计算机领域一次次上演。摩根士丹利预测：2040年，全球航天经济收入将超过1万亿美元，其中商业航天约占八成。近十年来，全球卫星产业总收入呈现增长态势。其中，卫星服务业和地面设备制造业最赚钱，国内外投资机构开始逐渐关注商业航天赛道。竞争对手，也越发多了起来。在海外，SpaceX丝毫不敢松懈，要时刻面对等民营航天企业的追赶。2019年11月15日，维珍银河已经启动了太空游客训练计划。之前，维珍银河推出的“太空游”票价，仅需25万美元，迅速引发600多人热烈追捧。随后，维珍银河为游客们专门设计了防弹宇航服，并推出医疗咨询和营养健身课程。如果不是新冠疫情，2020年年中，这些游客可能已经在遨游太空。SpaceX的另一劲敌蓝色起源，今年也造出了高速率火箭引擎BE-4，足以与同样使用液氧甲烷当燃料的、SpaceX的猛禽Raptor引擎相媲美。对世人来说，贝佐斯的“亚马逊”，让他登上了“世界首富”的巅峰。但在他心里，蓝色起源才是人生最重要的梦想。他认为，地球日益增长的能源需求将耗尽有限的能源。如果没有足够的能源，配给和饥饿就会接踵而至。于是在2000年，贝佐斯成立蓝色起源，每年投入10亿美元巨资，建造火箭、漫游车以及能飞越地球大气层的航天器。多年来，贝佐斯鲜少回应亚马逊的问题，却如同传教士般分享他的太空移民信仰：“WehavetogotospacetosaveEarth.”而放眼国内，2018年以后，中国民营商业航天企业也在加速发展，等企业竞相亮相，揭开了中国航天新篇章。2018年5月17日，零壹空间研发的OS-X火箭成功升空，成为民营自研商用亚轨道火箭的“第一射”。零壹空间CEO舒畅认为，在中低轨道上，商业开发一定是民营公司来做；而深空探测及月球基地、空间站，一定是国家队主导。2020年5月27日，星际荣耀的“焦点一号”可重复使用液氧甲烷发动机，成功完成二次启动长程500秒试车。也意味着中国民营航天企业实现了运载火箭垂直回收又一项核心技术突破。眼下，虽然SpaceX抢到了先机，但浩瀚的星际给中国也留下了巨大的空间。从蓝色起源、SpaceX创立算起，美国商业航天已走过近20年的历程。而中国直到2015年前后，才开始涌现商业航天企业。正是这短短几年时间，国内企业完成了从卫星设计研制、火箭研制发射，到卫星在轨运营、商业化应用的“0到1”的历程。以北斗导航、高景一号等重大专项突破为引领，中国商业航天企业不仅继续深耕导航、通信、遥感三大主流市场，也在扩展至卫星互联网、高通量通信、科研实验卫星等应用场景。2019年，全球共进行了103次航天发射（包括失败的发射），连续第二年发射“破百”。其中，俄罗斯以25次位居第二，美国则以21次排名第三。一边，是SpaceX发射了538颗“星链”卫星，以组建庞大的太空互联网；另一边，中国“北斗”坐拥200多颗卫星，以精准定位全世界。北斗系统的第55颗导航卫星，暨“北斗三号”的最后一颗全球组网卫星，也于2020年6月23日顺利进入预定轨道，比原计划提前半年完成。飞速发展的背后，既写满了心酸，也有中国特有的潜力和底气。1999年，美国国防授权法案禁止卫星及相关零部件出口中国，甚至包含美国元器件的卫星，都严禁由中国火箭发射升空。这项禁令，直接使得刚刚成熟的中国对外发射业务基本退出国际市场。2011年，美国的“沃尔夫条款”，又禁止中美两国开展任何与美国航天局有关或由白宫科技政策办公室协调的联合科研活动，甚至禁止美国航天局接待“中国官方访问者”。一直以来，美国都想利用市场换技术等手段，赢取或独占中国市场，利用技术控制，消耗创新动力，最终阻断中国的技术突破与发展。这显然低估了中国。从“东方红”到“北斗”，从“神五”载人到“嫦娥一号”，中国不仅在多个领域突破封锁，成为具备独立建造空间站、探索月球能力的航天强国，也开始实施技术反封锁。▲嫦娥四号探测器成功登陆月球背面实现了人类探测器首次月背软着陆“国家队是集中力量办大事，而我们是有力候补。”一位商业航天公司高管表示。2014年4月，九天微星CEO谢涛在一场峰会上见到了马斯克。当时，门票被炒到3000元一张，他咬咬牙，买票进场。他至今仍记得，马斯克在演讲开场放了一段视频：SpaceX的“猎鹰”火箭穿云箭一样扎入天宇，又精准找到了海上回收平台，稳稳降落。台下人群里，谢涛瞪大了眼。4年后的2018年2月，九天微星的第一颗星，3公斤重的“少年星一号”，在酒泉由长征二号丁运载火箭发射升空。自此之后，孩子们能在课堂上与卫星互动，学校可通过卫星采集候鸟的迁徙数据，用于地理教学。2020年，当新基建的春雷响起，原本曲高和寡的卫星互联网、商业航天产业，突然迎来了爆发式增长的机会。可以预见，企业间、大国间的“空天之战”将更加多元激烈，而在这场决定无限未来的竞争中，人类必将走向真正的星辰大海。一一END一一图片均来自网络',
 'publish_time': '2020-06-30 13:34:00',
 'title': '“疯狂”马斯克，逐梦“太空圈”',
 'url': 'http://baijiahao.baidu.com/s?id=1670900922521341165'}
2020-06-30 19:58:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301325297.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9974985944910120081%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301325708.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9673743913752797710%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670842465572337534> (referer: http://news.baidu.com/)
2020-06-30 19:58:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670842465572337534>
{'content': '三言财经消息，据阿里内网通报内容，淘宝直播UGC&频道运营负责人赵阳（赵圆圆）在关联业务合作伙伴处任职/提供服务，利用职务便利为其关联人士和合作伙伴谋取不正当利益，接受礼品及款项。通报具体指出，赵阳（赵圆圆）在2018年1月结识淘宝某直播机构负责人，在该机构申请入驻服饰直播基地被拒绝后，赵阳（赵圆圆）帮助该机构成功入驻。2019年4月，赵阳（赵圆圆）通过上述直播机构负责人，安排女友以高薪入职该机构。通报还指出，赵阳（赵圆圆）收受礼品和款项，为多家淘宝直播机构的主体提供兼职服务。处理决定对其予以辞退处分，并处以永不录用。据了解，6月28日赵圆圆发布朋友圈并配文：“欲加之罪何患无词”，但目前该条朋友圈内容已被删除。今日下午，赵圆圆在微博发布了一张“吃瓜图”。随后，据凤凰科技消息，赵圆圆回应称，“我的为人、我做了什么事情，圈里人都知道”。阿里巴巴拒绝回应此事。赵圆圆拒绝对此事进行评论，他说，今天朋友圈一堆人都发了相关消息给他，“这无所谓”。他表示，现在自己正在筹备一家MCN机构的创业，正忙着装修公司，“找场地、装修已经费了我好多精力了，其他的都顾不上了”。据悉，赵圆圆，本名赵阳，1979年生人。2017年8月加入阿里负责淘宝直播之前，从事市场营销工作15年，曾在奥美担任资深创意总监。2017年8月加入阿里后负责淘宝直播。曾任阿里巴巴内容电商事业部资深专家、淘宝直播负责人。今年3月份赵圆圆从阿里离职，有报道称赵圆圆离职后下一步是创业做一家MCN机构，阿里会是投资方之一。赵阳工号阿里集团-淘宝事业群-内容电商事业部-直播UGC＆频道运营资深内容运营专家时任主管陈镭（闻仲），俞峰（玄德）；时任HRG何逸盈（妮柯），吴小芬红棉）违规事实赵阳在关联业务合作伙伴处任职/提供服务，利用职务便利为其关联人士和合作伙伴谋取不正当利益，接受礼品及款待2018年1月起，赵阳开始担任淘宝直播UGC＆频道运营的业务负责人，并结识淘宝某直播机构负责人。2019年1月，该机构申请入驻服饰直播基地，服饰基地审核小二（赵阳的二级下属）按照规则对该机构的申请予以了拒绝，赵阳随即找到该小二，以该等级的机构发展基地业务可以与平台更好的合作为由，提出修改原有规则，并明确要求审核小二对此申请予以通过。后该机构成功入驻。2019年4月，赵阳通过上述直播机构负责人，安排自己的女友以高薪入职该机构。至2019年10月，其女友从该机构处共领取薪资数十万元，而其之前在另一家直播机构任职时，月薪不足7000元。2019年9月，赵阳借出差之际以淘宝直播负责人名义参加外部商业大会并收取3万元费用。2018年至2019年期间，赵阳分别接受多家直播机构提供的餐饮、住宿及礼品，累积金额约5800元。同时，赵阳为多家淘宝直播内容机构的主体公司提供兼职服务。处理决定赵阳的行为构成《阿里巴巴员工纪律制度》一类违规第1.4.1项“利用职务便利，为本人或他人谋取不正当利益“、一类违规第1.4.3项“接受其他款待未申报且价值较大、收受礼品未上交也未归还且数额较大”以及一类违规第1.4.4项在公司供应商、合作伙伴、签约商户及/或竞争方处任职”。对赵阳予以辞退处分，并处以永不录用。',
 'publish_time': '2020-06-29 22:05:00',
 'title': '被阿里通报违规，赵圆圆：我的为人，圈里人都知道',
 'url': 'http://baijiahao.baidu.com/s?id=1670842465572337534'}
2020-06-30 19:58:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670883529085697077> (referer: http://news.baidu.com/)
2020-06-30 19:58:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670883529085697077>
{'content': '文|AI财经社乔迟编辑|鹿鸣6月29日，深交所向全聚德出具年报问询函，要求全聚德就营业收入、净利润、扣非后净利润和经营现金流持续下滑，经营现金流波动较大等事项作出说明。全聚德2019年年报显示，其在2019年实现营收15.66亿元，同比下降11.87%；归母净利润4462.79万元，同比下降38.9%。实际上，这已经是全聚德业绩停滞不前的第8年，也是其自2007年上市以来净利润最低的一年。在近三年里，全聚德的年报成绩逐年下滑。2017年、2018年、2019年，全聚德分别实现营业收入18.61亿元、17.77亿元、15.66亿元；实现净利润1.36亿元、0.73亿元、0.45亿元；扣非后净利润1.19亿元、0.57亿元、0.20亿元；经营现金流2.24亿元、0.80亿元、0.69亿元。深交所要求全聚德结合行业状况、竞争格局、主营业务开展情况，以及报告期内公司毛利率、期间费用、非经常性损益构成等因素的变化情况，说明公司营业收入、净利润、扣非后净利润和经营现金流持续下滑的原因。在2019年年报中，全聚德第一至四季度分别实现营业收入4.01亿元、3.57亿元、4.33亿元和3.75亿元；经营现金流分别为-0.19亿元、0.29亿元、0.75亿元和-0.16亿元。深交所要求全聚德说明在四个季度营业收入分布较平均的情况下，经营现金流波动较大的原因。在年报中的营业收入构成部分，AI财经社注意到，除了华中和华中部分，剩下地区对于营业收入的贡献非常小，尤其华北业绩稍亮眼，撑起了其他地区的亏损。说明全聚德还面临着在北京之外的地区的“水土不服”。全聚德在华北地区的营收约占总营收的100.37%，远超排在第二位的华东地区的15.7%。而在业绩变化上，除华中地区的营收较2018年有所增加外，华北、华东、西北、东北、西南等地均有所减少。另据全聚德历年财报显示，2017年至2019年，其餐饮业务全年接待宾客分别为804.07万人次、770.47万人次、658.92万人次，短短两年时间，就已经缩减了约150万人次。此外，全聚德4月发布的一季度报告也十分不乐观。报告显示，受疫情影响，全聚德1-3月录得营收1.80亿元，同比减少55.03%；净利润亏损8850.10万元，同比减少931.66%；经营活动产生的现金流量净额为-5442.76万元，同比减少180.55%。对于业绩惨淡的原因，全聚德表示，是因为新型冠状病毒肺炎疫情对整体餐饮经营环境产生重要且持续性的负面影响，公司的餐饮及食品业务均受到严重影响，导致公司第一季度营业收入大幅下降，净利润出现亏损。全聚德坦言，预计新冠疫情对业务的影响还将持续，持续时间存在不确定性。作为一家全国闻名的百年老字号，全聚德自1864年成立以来，已经走过了156个年头。对于很多人来说，全聚德一度是北京烤鸭的象征，也是外地游客来京几乎必吃的北京名小吃。1993年5月，中国北京全聚德集团正式成立，一年后改制为股份制公司，并于2004年划归首旅集团，最终更名为中国全聚德（集团）股份有限公司。2007年，全聚德在深交所挂牌上市，成为首家在A股上市的餐饮“老字号”企业，被称为“烤鸭第一股”。资本助力下，全聚德曾一路高歌猛进。2007年，其营收尚为9.17亿元，到2012年，这一数字就已经翻倍至19.44亿元。在达到2012年的峰值后，全聚德不但没有如很多人预期所想，成功突破20亿元大关，反而节节败退。数据显示，2012年至2019年，全聚德营收分别从19.44亿萎缩至15.66亿，归母净利润从1.52亿萎缩至4462.79万。在利润和口碑下滑的同时，全聚德的投资却很大手笔。深交所在问询函中表示，全聚德长期股权投资余额为3.80亿元，同比增长392.02%，要求全聚德补充披露长期股权投资大幅增长的具体原因、投资主体、投资目的、所占股权比例等。财经天下周刊查询年报发现，全聚德股权资产长期股权投资同比增幅392.02%，主要是公司投资首旅集团财务公司所致。据年报中介绍，首旅集团财务公司的主要业务是对成员单位办理财务和融资顾问、信用鉴证及相关的咨询、代理业务；协助成员单位实现交易款项的收付；经批准的保险代理业务；对成员单位提供担保；办理成员单位之间的委托贷款等。全聚德对首旅集团财务公的投资金额为3.06亿元，持股比例为12.50%，本期投资盈利了182.3万元。合作方有控股股东首旅集团及关联方王府井、首商股份、首旅酒店共五方以现金方式共同增资首旅集团财务公司。此外，全聚德还投资性房地产同比增幅2396.71%，主要是公司对外出租房产涉及的资产由固定资产转入投资性房地产科目核算所致。据2019年年报显示，全聚德的投资活动现金流入小计11.13亿元，同比增幅55.86%；投资活动产生的现金流出小计1.4亿元，同比增幅87.97%；投资活动产生的现金流量净额同比降幅820.96%，主要是本年度累计购买、赎回结构性存款增加及投资首旅集团财务公司所致。现金及现金等价物净增加额同比降幅718.54%，主要是投资活动使得现金流出所致。2017年、2018年、2019年，全聚德分别实现投资收益0.36亿元、0.41亿元和0.55亿元，占同期净利润的比例分别为26.23%、55.60%和123.64%。深交所要求，全聚德列示2019年投资收益的具体构成、计量方法、确认依据，并结合公司盈利模式分析说明近三年投资收益及其占净利润比例持续增长的原因和可持续性。',
 'publish_time': '2020-06-30 08:58:00',
 'title': '业绩连续下滑，全聚德遭深交所问询，两年丢掉150万顾客',
 'url': 'http://baijiahao.baidu.com/s?id=1670883529085697077'}
2020-06-30 19:58:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670900695105270086> (referer: http://news.baidu.com/)
2020-06-30 19:58:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670900695105270086>
{'content': '1据CNN，当地时间6月29日，加拿大太阳马戏团的母公司太阳马戏团娱乐集团申请破产保护，魁北克高等法院将在6月30日审理这一申请破产保护的案件。如果得到批准，太阳马戏团接下来将在美国寻求破产保护。受新型冠状病毒蔓延的影响，太阳马戏团已经在三个月内暂停了所有演出。多份报告显示，太阳马戏团负债累累，负债额度达到近10亿美元。穆迪投资服务公司在今年初将太阳马戏团的信用评价降到“垃圾级”，警示其有违约风险。该机构分析指出，太阳马戏团的产品运营结构单一，令其容易暴露在无法控制的事件中，例如自然灾害、消费者收入和可支配支出的变化、其他竞争对手的竞争等。事实也确实如此。随着疫情蔓延，太阳马戏团在拉斯维加斯的6场驻演大秀早已关闭，全球巡演的44场演出也宣告停摆。随着演出暂停，太阳马戏团的经营状况变得越来越难以为继。为了阻止进一步的财务损失，太阳马戏团于今年3月裁减了近95%的员工。该公司CEO丹尼尔.拉马（DanielLamarre）表示：“由于新冠病毒导致我们所有节目被迫关闭，公司收入为零，管理层必须果断采取行动保护公司的未来。”太阳马戏团目前已与现有投资者私募股权基金TPGCapital、中国复星国际，以及加拿大养老基金魁北克储蓄投资集团签署一项协议，根据协议，该财团将接管太阳马戏团的负债，并投资3亿美元以支持其重启。美国TPGCapital是太阳马戏团的主要股东，持有60%的股份，而复星国际和魁北克储蓄投资集团分别持有20%的股份。TPG、复星和魁北克储蓄投资集团还将负责一个1500万美元的员工基金，为下岗员工提供经济援助。5月25日，加拿大太阳马戏团官方微博宣布，将从6月3日起，正式恢复在中国杭州新天地太阳剧场的驻场秀演出《X绮幻之境》，而这也是太阳马戏娱乐集团在全球范围内首个复演的项目。《X绮幻之境》有来自12个国家的20多位外籍演员参与演出，根据太阳马戏团官博公告，4月初，包括外方演员在内的所有演出人员就已回归剧场参与日常排练。',
 'publish_time': '2020-06-30 13:21:00',
 'title': '太阳马戏团申请破产，曾裁员近95%',
 'url': 'http://baijiahao.baidu.com/s?id=1670900695105270086'}
2020-06-30 19:58:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9758348043604443041%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
2020-06-30 19:58:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9758348043604443041%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670893602283404530> (referer: http://news.baidu.com/)
2020-06-30 19:58:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670893602283404530>
{'content': '鞭牛士6月30日消息，天眼查数据显示，近日，湖北珞珈梧桐创业投资有限公司发生工商变更，雷军卸任董事。但雷军仍为该公司股东，持股比例为4%。',
 'publish_time': '2020-06-30 11:37:00',
 'title': '雷军卸任湖北珞珈梧桐创业投资有限公司董事',
 'url': 'http://baijiahao.baidu.com/s?id=1670893602283404530'}
2020-06-30 19:58:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670895742616004589> (referer: http://news.baidu.com/)
2020-06-30 19:58:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670895742616004589>
{'content': '来源：新浪财经6月30日消息，新浪财经从中国裁判文书网获悉，广东省深圳市南山区人民法院发布一则民事裁定书，同意原告腾讯请求查封、冻结被告老干妈公司公司名下价值人民币16240600元的财产。公告显示，原告深圳市腾讯计算机系统有限公司诉被告贵阳南明老干妈风味食品销售有限公司、贵阳南明老干妈风味食品有限责任公司服务合同纠纷一案中，原告提出财产保全的申请，请求查封、冻结被告两公司名下价值人民币16240600元的财产。法院认为，原告的申请符合法律规定，裁定查封、冻结被告贵阳南明老干妈风味食品销售有限公司、贵阳南明老干妈风味食品有限责任公司名下价值16240600元的银行存款或查封、扣押其等值的其他财产。裁判文书中仅称，腾讯诉老干妈此案是因为服务合同纠纷，未提及具体纠纷事项，腾讯方面也暂未对此事做出公开回应。天眼查显示，贵阳南明老干妈风味食品有限责任公司有两位股东，李妙行持股51%、李贵山持股49%，据悉二人均为陶华碧亲属，其中李贵山是陶华碧长子。另外，贵州南明老干妈风味食品销售公司是贵阳南明老干妈风味食品有限责任公司的全资子公司，老干妈创始人陶华碧为前者执行董事兼总经理，为后者董事长兼公司法人。',
 'publish_time': '2020-06-30 12:08:00',
 'title': '腾讯请求查封贵州老干妈公司1624万财产',
 'url': 'http://baijiahao.baidu.com/s?id=1670895742616004589'}
2020-06-30 19:58:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670893713637541420> (referer: http://news.baidu.com/)
2020-06-30 19:58:40 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670893713637541420>
{'content': "图片来源@视觉中国近期，社交巨头Facebook的日子不太好过。在黑人之死风波愈演愈烈的情况下，Facebook却对相关言论放任自流，使得其成为了抵制榜单之首，更加值得注意的是，支持抵制榜单的跨国巨头越来越多了。截至目前，包含英国消费产品巨头联合利华、美国电信巨头Verizon、可口可乐、冰淇淋制造商Ben＆Jerry's以及宝洁、本田等多家大型企业在内的160余家企业都宣布暂停在Facebook社交平台上投放品牌广告。此前，参与抵制的大多为中小企业，如今随着大企业的逐渐加入，Facebook在股价和形象上承受的压力或将更大。表现在资本市场，虽然Facebook本周一股价上涨了2%左右，但据美股研究社调查显示，截至上周五美股收盘，Facebook股价暴跌8.32%，创下了近3个月以来的最大跌幅，市值减少越560亿美元。与此同时，扎克伯格的个人身价迅速缩水超70亿美元。根据彭博亿万富翁指数，扎克伯格的财富先前估计为895亿美元，缩水后将从榜单上下降一位至第四位关键是，在扩大全球影响力的同时，组织者还将继续鼓励更多美国企业参与其中。FreePress联席CEO杰西卡·冈萨雷斯表示，她与美国大型电信和媒体公司联系，希望他们也能加入这项运动。这意味着，这一轮广告抵制潮还有后浪。Facebook需要快速、有效地解决这个问题，才能阻止广告撤离失去控制。因为，随着越来越多的Facebook广告主宣布暂停投放社交媒体广告以及大型企业加入这场抵制潮之后，Facebook除了股价要承受巨大压力之外，公司营收前景也可能蒙上一层阴影。对Facebook的业绩影响究竟会有多大？作为全球的社交巨头，Facebook坐拥Facebook、WhatsAPP、Instagram三大平台，全球活跃用户数超过30亿，而广告正是其收入支柱。财报显示，今年一季度Facebook营收177.37亿美元，其中广告收入174.4亿美元，占比高达98.3%。去年Facebook的总营收为706.97亿美元，广告收入达697亿美元，广告客户超过800万家。广告于Facebook的重要性，已不言而喻。据Needham&Co．的行业分析师发现，在Facebook的广告收入中，大型品牌所占比例正越来越大，这意味着，随着大品牌加入广告抵制行列后，给Facebook的广告业务带来打击是毋庸置疑的，但究竟会给业绩带来多大影响？我们不妨来看几项具体数据。在此次参与抵制的广告商中，不少企业在Facebook平台上的广告支出不容小觑。相关数据显示，2019年联合利华在Facebook广告投入超4200万美元，位居第30位；而Verizon位居第88位，广告投入的费用自然也小于联合利华；同期，可口可乐在Facebook平台广告支出2210万美元。但2019年Facebook前100名广告商所占其广告收入的份额仅有6%，而家得宝、沃尔玛、微软、迪士尼等排在榜首的广告主均为加入抵制行列。事实上，在Facebook每年约700亿美元的广告收入中，有约四分之一是来自联合利华等大型公司，其中绝大部分收入来自小型企业。这样看来，目前这些企业的广告抵制对Facebook的业绩影响，在有限范围之内。而且由于受到各方压力，扎克伯格也在26日表态称，Facebook将开始打击针对特定种族和族裔的压制行为。不过，反诽谤联盟CEO乔纳森·格林布拉特（JonathanGreenblatt）表示，“广告主不停地给我们打电话。我可以肯定的是，此事没有就此结束。”依赖广告生存的其他社交平台们，“危机”之下该如何思变？目前的抵制行动已扩展至包括Twitter在内的网上广告平台，星巴克周日也表示，停止在所有社交媒体平台上落广告，以期阻止仇恨性言论的传播。这样的状态，对于高度依赖数字广告业务的平台们而言，要说没有利益损伤几乎是不可能的。只不过，抵制对互联网媒体平台究竟会产生多大的冲击，在分析人士看来，目前尚难下定论。从今年广告业务的大环境来看，在疫情的影响下，不少企业的营收都受到了影响，绝大部分广告商缩减了相关费用的支出。整体而言，广告业务的处境本就不太乐观，相较于去年而言，广告投放的下滑是肯定的。Twitter在五月份有表示称，其广告收入在四月份有下降27%；谷歌母公司Alphabet也警告说，四月早期的趋势或不可持续，二季度销售将较为艰难。只不过，这一状态下，企业倒是更加倾向于将广告业务从传统媒体向互联网平台转移。因为互联网公司通常可以通过大数据提供效果付费广告，在行业大环境备受挑战以及资金有限的情况下，广告商往往会选择可以看得见明显效果的付费广告，而疫情期间正好培养了用户线上打发时间的习惯，广告商青睐数字化广告也是无可厚非。这恰好增强了社交媒体平台等互联网企业的抗压能力。Snap4月份的在线销售增长到10年来的最高水平，同比增长23.8％；Facebook广告收入历经3月份的急剧下滑之后，四月与去年基本持平。从这些现象来看，整体广告业务的基本面已经趋于稳当。总之，目前的广告行业可以说是大环境不容乐观，但数字化广告还是有值得进一步发掘的空间。那么，在如今疫情和广告抵制潮的双重打压下，社交媒体或许更应该参考这些能够逆势增长的企业。比如，Snap的逆势扩张。疫情之下，snap宣布将去年秋天推出的动态产品广告拓展到欧洲，中东和澳大利亚等更多国家，真正开始在全球扩张。逆势增长的背后Snap还从Facebook，Amazon、Google等一些领先的数字公司聘请广告销售人员，以及建立跨越许多站点和应用程序的广告网络，为的就是解决如何为广泛的品牌提供用户体验，而不仅仅是从D到C的直接响应广告客户。归根结底，任何企业要在困境中前行，到头来拼的还是自身的竞争力和应变能力。“抵制潮”，或加速Facebook的多元化之路？Facebook除了广告收入，其他部分的收入微乎其微，这些年来，Facebook的用户增长天花板逐渐显现，过于单一的营收模式隐患正在凸显。实际上，社交之外，Facebook也在疯狂探索其他的营收渠道。2013年开始，Facebook将更多目光聚焦到了消费硬件领域。彼时，Facebook与HTC合作推出了一款定制款智能手机HTCFirst和一款Android桌面应用FacebookHome，但并没有激起很大的水花，最终以惨败收局。不过，这并没有影响到它进军硬件的野心。2014年，Facebook耗资23亿美元收购了Oculus，对AR投下重注，以此为根基在硬件领域取得了一些成绩；去年9月，Facebook以7.5亿美元的价格收购了脑机接口初创公司CTRL-labs。虽然，整体而言Facebook在硬件领域并未有重大业绩突破，但这一系列动作的背后均表露了Facebook想走多元化道路的意图。金融支付领域，Facebook也不甘落后。今年四月份，Facebook公布了其史上第二大的一笔投资，以57亿美金拥抱亚洲首富MukeshAmbani旗下的印度公司JioPlatforms，随后在6月初，Facebook投资了3亿美金以换取Gojek旗下支付业务GoPay2.4%的股份。虽然，本月初，其即时通讯软件WhatsApp，在巴西推出的应用内付款服务在首次亮相不到两周的时间，便在巴西暂停了。但有了在印度和印尼的两笔投资之后，后续Facebook在金融领域仍然有看头。相比在硬件、和金融支付领域的试探，Facebook在电商业务的布局或许引起了市场的更多关注。今年5月份Facebook宣布推出电商功能后，股价应声大涨。可见，二级市场对Facebook做电商抱有较高的期望。在此前的公告中，Facebook表示将与Shopify、BigCommerce和WooCommerce等专注服务DTC品牌的电商平台展开紧密合作。就双方而言，Shopify从用户体量庞大的Facebook的电商化转型中势必会获得巨大收益；而Facebook与拥有庞大客户群的Shopify合作，则可以更快的吸引更多品牌以及零售商来入驻、吸引大量用户来平台购物。那么，基于Facebook十亿数目的用户基础，它是极有可能在电商领域带动更多流量变现的。如今，广告抵制潮的来袭，使得Facebook高度依赖数字广告的弊端进一步凸显。某种程度上来讲，这会加速Facebook的多元化发展。长期来看，未来的Facebook或许不再过于依赖数字广告，将以一个多元化的姿态出现在世人面前，但就眼下承载着社交巨头身份的Facebook而言，这条路依然道阻且长。【钛媒体作者介绍：美股研究社（meigushe），旨在帮助中国投资者理解世界，专注报道美国科技股和中概股，对美股感兴趣的朋友赶紧关注我们。】",
 'publish_time': '2020-06-30 11:32:00',
 'title': '广告业务被抵制，Facebook怎么办？',
 'url': 'http://baijiahao.baidu.com/s?id=1670893713637541420'}
2020-06-30 19:58:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670883546900821885> (referer: http://news.baidu.com/)
2020-06-30 19:58:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670888789448707638> (referer: http://news.baidu.com/)
2020-06-30 19:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670883546900821885>
{'content': '燃财经（ID:rancaijing）原创作者|赵磊编辑|魏佳2020上半年，直播带货成为中文互联网世界津津乐道的新风口，李佳琦、薇娅高调出圈，舆论甚至隐隐将“直播”和“带货”划上等号，许多人以为看直播就是买东西，相比之下，作为直播鼻祖的秀场直播，则比以往更为低调，鲜少出现在公众视野中。事实上，主要靠女主播唱歌跳舞赚钱，习惯了“闷声发大财”的秀场直播平台，现在的确过得没有以前那么舒服。直播社交平台陌陌在2020年一季度的收入和利润双双下降，欢聚集团旗下的YY收入和利润也是负增长，“港股直播第一股”的映客更是徘徊在亏损的边缘。陌陌CEO唐岩把这种下滑归结为疫情影响：“宏观经济——特别是私营企业主的经营状况，对于头部消费的负面影响还会持续一段时间。”简单来说，那些有钱的土豪老板们自己都经营不善，哪还有钱打赏女主播？疫情是一方面，但秀场直播平台的颓势也不是一天两天了。2019年上半年，映客就已经出现亏损情况，尽管此前13个季度一直在盈利，营收利润却是连年下降，股价也跌跌不休；陌陌则是增长乏力，月活跃用户卡在1.1亿，付费用户也上不去，连累收入增长；YY虽然一直比较稳定，但欢聚集团的业务重心早已放在海外，YY成为现金奶牛，给新业务供血，变相放弃了国内市场的争夺；曾被周鸿祎看好的花椒直播，也早已失去了360这个强硬后台，几乎销声匿迹。“传统的秀场直播平台都遇到增长天花板，寻求转型，根本上还是秀场直播这个模式本身的问题。”互联网分析师张默对燃财经表示。秀场直播中，人就是内容本身，直播的工具属性最强，平台是很难留住人的，只有高消费的头部用户黏性会强一些，但这部分人群规模有限，导致的结果就是，平台整体用户规模上不去，只能提升老用户的付费水平，这就有了明显的天花板。深挖人性，是秀场直播平台最擅长的，在这个名利场中，永远不缺青春靓丽的年轻姑娘，也不缺千金一掷的土豪，但秀场直播的故事，怕是讲到头了。老板没钱打赏女主播了孙毅鹏在一家直播公会负责主播招募，最近几个月，他明显感觉到主播的流动率高了不少，自己身上的任务也越来越重。流动率高的原因，一方面是疫情期间很多人想用待在家里的时间挣一些钱，所以报名的人比往常多了不少，另一方面是秀场直播现在不好干，一些经验丰富的主播都离开了，新人更难坚持下来。一位主播跟他说，这几个月的平均收入下降了30%，去年给她打赏二十多万的榜一大哥已经消失许久，其记录至今无人打破。“经济形势不好，愿意充钱的人少了，主播却多了很多，竞争更激烈。”孙毅鹏说。主播数量变化只是孙毅鹏的直观感受，但收入下降确实是整个行业的现状，从几大秀场直播平台的财务数据可以看出，陌陌财报显示，2020年Q1营收同比下降3.5%，环比下降23%，主要受到直播业务收入下降的影响，该部分收入仅为23.32亿，同比下降13%，环比下降31%，这导致陌陌Q1的经调整净利润仅为7.35亿，同比、环比分别下降19%和43%。YY的情况也差不多，Q1营收26.3亿，同比下降4%，环比降幅高达21%，经调整净利润则同比、环比分别下降了24%和37%，仅为4.86亿。当然，所谓受创也是和之前相比，陌陌、YY的营收和利润在直播行业仍然让他人艳羡，尤其是和虎牙、斗鱼等盈利能力差一些的游戏直播平台相比。陌陌Q1毛利率高达48%，相比前几季度已经有所下降，而Q1表现亮眼的斗鱼，毛利率依然只有21%。“从收入和利润看，不管陌陌还是YY，活得依旧很滋润，但投资者更关心它们未来怎么样，这次的负增长是受疫情影响，还是业务深层次驱动的拐点，才是问题的关键。”张默说。从股价表现来看，这三家老牌秀场直播公司的走势已出现分化。今年1月以来，陌陌的股价已经从高点40美元一路下跌，6月29日收盘价仅17.5美元，市值蒸发了一半以上。YY母公司欢聚集团则股价表现强劲，从60美元涨到90美元，张默认为，这或许是因为陌陌扎根国内，对直播依赖更大，欢聚集团的海外业务增长亮眼，短视频和直播双轮驱动，转型更顺利。陌陌还有一张陌生人社交的牌可以打，收购探探后，陌陌再无强敌，稳坐陌生人社交头名，目前以交友虚拟礼物和会员为主的增值服务收入也维持着不错的增速，占陌陌总体营收的比重达到32%。相比之下，直播收入占比高达99%的映客，日子真的不好过。短短半年，港股上市的映客已经进行了58次股票回购，但连续的回购依然没能阻挡下行的股价，较今年2月的纪录高点累计跌近30%，市值缩水三分之一，目前仅为22亿港元。一位直播行业人士对燃财经表示，映客直播当年打出“移动直播第一股”的旗号，先于虎牙和斗鱼上市，但其实本身体量一直不大，在行业进入洗牌阶段后，抗风险的能力差很多，“加上疫情影响，转型会更困难，有可能就此一蹶不振”。“秀场直播是做人的生意，人聚财聚，哪里人多去哪里，所以头部聚集效应会强一些，小平台用户量少，公会和主播都离开去了大平台，形成恶性循环，就很难再做起来。”他说。与欣欣向荣的直播带货比，秀场直播这个“老掉牙”模式真的已经走到头了吗？曾经躺赚，如今发愁2016年，移动互联网大潮汹涌，随着4G网络提速降费，在PC互联网时代仅被用于“线上KTV”的直播，也带来了新的故事，即全民直播，类型也丰富多样，吃饭睡觉唱歌跳舞打游戏，直播就是生活本身。想象很美好，现实却很残酷，千播大战，资本竞逐，规模效应、一家独大的互联网故事被反复讲起，杀红眼的人没有解决两个本质问题，一是主播为什么要直播？二是用户为什么要看直播？第一个问题导致的结果是“全民直播”回到了秀场直播的老路，唯有资本持续输血的游戏直播是个例外；第二个问题导致作为一种重度娱乐行为，直播的用户规模一直上不去，远低于长视频以及后来兴起的短视频。“现在可能这种趋势更明显一点，直播被应用于各行各业，但如果做纯粹的工具和平台，就是我给你提供一个直播间，你播什么无所谓，有人打赏你我就抽成，这样的公司是很难持续的。”一位文娱投资人对燃财经表示。千播大战时期主打“全民直播”的平台，大都死掉了，问题就是管道化、无门槛、留不住主播和用户、变现难，今天活下来且活得好，以及新出现的这些玩家，大多只是把直播当成输出平台内容和流量变现的工具。YY、陌陌和映客现在走的路线差不多，都是“直播+社交”，不过在产品上各有偏好。陌陌的陌生人社交元素更重，基于地理位置进行直播社交，打赏、送礼搭讪美女；YY则像是去了KTV，谁花钱多谁就是大哥，公会紧密控制主播，互相争斗不止，满满的江湖气；映客都有，但都不够彻底，整体上更像陌陌。都是直播，YY们和淘宝直播、抖音直播几乎完全不一样，去看淘宝直播的人是为了买便宜产品，抖音直播间打赏的人是支持自己喜欢的网红或明星，在YY一掷千金的人，无一不和公会、主播、房管、其他上榜大哥有着千丝万缕的社交联系。从商业模式上看，秀场直播具备天然的高毛利率。人就是内容本身，也是运营的对象，直播公会把主播聚合起来，教这些漂亮姑娘如何打造“有趣的灵魂”，如何用自己的巧舌挑动观众情绪，如何制造和巧妙化解大哥之间的纠纷，不仅提高了平台收入，还大大降低了平台的运营成本。相比之下，“游戏直播就很惨，一来游戏打得好的人很少，二来很少会有人因为你游戏打得好而打赏，三是头部主播要价高且难管，这就是为什么斗鱼一直有流量但不赚钱。”一位接近斗鱼的人士表示。从一开始，游戏直播和秀场直播就背道而行，虎牙、斗鱼的苦日子过久了，现在有腾讯在背后撑腰，反而越走越顺，但秀场直播习惯了躺着赚钱的好日子，一直都是自给自足，现在却要发愁了。秀场直播转型难在哪儿？除去短期内疫情的因素，摆在秀场直播平台面前的问题有两个，一是增长，二是竞争。我们从三个维度来看看陌陌、YY、映客的增长。从营收看，陌陌和YY的直播业务营收增速都不高，陌陌稍好，维持在15%左右，YY则在10%左右，但增速都在下滑，Q1都出现了负增长。映客半年公布一次业绩，2018年下半年和2019年上半年都出现负增长，2019下半年回升到13%，全年跨度看，营收已经连降三年。从月活跃用户情况看，陌陌已经横盘在1.1亿很长时间，YY此前也保持在4000万左右，但Q1有较大增幅，说明看直播的人有所增长，但从付费用户数看，不管YY还是陌陌，都在上下波动，没有明显增长，陌陌是900万左右，YY在420万左右。映客用户规模更小，截至2019年底仅有2980万MAU。增长难已经是秀场直播行业公认的事实，，分走用户的小平台不计其数，商业模式导致这些小平台的生存并不困难，孙毅鹏透露，有些小平台给到公会和主播的分成更高，反而更赚钱。秀场直播门槛低，主播和公会之间竞争激烈，对于在平台没什么势力的主播和公会来说，转战流量更高的平台可能是更好的选择，。YY在这件事上吃了大亏，最早的时候，快手和YY是合作关系，YY作为变现渠道，快手是低价流量池，后来快手自己做直播，YY一些不出名的主播转战快手，迅速逆袭，比如红极一时的天佑，大量YY主播出走快手，也重创了YY的直播生态。“快手的用户可能没有YY的头部土豪那么能充钱，但用户基数大，每个人少充点，整体就是很大规模的流水，一些没有大哥支持的中小主播也更容易赚到钱，你在快手建立的是另一种关系。”孙毅鹏表示。抖音也在发力，到了2019年底，抖音和快手两家的直播收入和用户规模已经远远超过陌陌和YY。快手仅游戏直播的日活用户就高达5100万，直播业务整体营收约为300-350亿，抖音直播的月流水也已经和快手差距不大。上述投资人认为，秀场直播的增长和竞争问题其实内因只有一个，“从社交关系来说，秀场直播是很容易排斥新玩家的，你进到一个直播间里，除非你是颠覆者，用钱砸一个地位出来，不然你没有什么归属感，普通用户黏性很差，但头部用户忠诚度会比较高。”对特定用户群体的依赖度越高，转型越困难。以这三家来说，陌陌潜力更大，其陌生人社交的属性依旧很强，月活用户规模最大，很大一部分用户是奔着交友去的，基于社交需求的增值服务收入占比已经很高了，也能探索出更多的玩法。YY和映客就有点难了，欢聚集团已经将重心放在了海外，未来不会在YY上投入更多，巧妙地避开了矛盾点，集团整体的用户、收入、股价都维持良好的增长态势，可以说已经找到了第二增长曲线。映客一没有陌生人社交基本盘，二没有出海动向，一直强调“泛娱乐+社交”布局，先是高价收购积目，再持续不断推出娱乐新产品，但都没有亮眼的表现。秀场主播带货，靠谱吗？传统的秀场直播模式，毫无疑问已经讲不出新故事了，但长期盈利和充足的现金储备，给秀场直播平台留下了战略腾挪的空间。“虽然预期不好，但这几家短期内都不会有什么问题，还能维持盈利很长时间，直播业务能给新业务持续供血。”张默说。孙毅鹏同样认可秀场直播，“这个模式持续了十几年，肯定是有门道的，哪个男人不喜欢美女？普通人去KTV，土豪老板就喜欢在直播间被人崇拜，喜欢女主播当着几千几万人的面儿叫自己一声大哥，这个改变不了。”新华网电商负责人王盛也认为，中小企业的私营老板是秀场直播打赏的主力，疫情过后就会恢复常态，“这是个现金流很好的业务，还是挺稳定的，毕竟中国人口基数大，而且秀场直播利用的是人性中的一些弱点，所以一定是持久存在的，不会说倒就倒。”在直播业务上，秀场直播能不能赶上2020年直播带货的大风口？事实上，这三家秀场直播平台都进行了尝试。YY在App内设置了叫做直播购的直播带货频道，品类非常垂直：只有手镯、玉器、文玩等珠宝商品，直播间列表在封面上展示出来的，都是正在销售的商品。这些直播内容并非直接由YY提供，而是来自于旗下的珠宝电商平台“一件”，里面的主播来自于入驻商家。陌陌CEO唐岩在Q1财报电话会议上说：“公司确实看到了电商与网络直播相结合的这样一个上升的趋势，也在非常积极地研究和探索一些潜在机会。但在这一点上，目前还不会公开分享更多深入的消息。”据Tech星球报道，陌陌集团成立了直播电商部，团队规模在50人左右，准备今年大力发展带货直播。陌陌BD人员现在四处寻觅有一定粉丝基础、有特长的主播，而且可以帮助主播与现机构赔偿转换公司的违约金。但签约来的带货主播，实际上并不是在陌陌直播，而是在淘宝直播上卖货。映客开设了“嗨购”的直播带货专区，并给带货主播设定了公开的GMV引导任务，分为从1000元一直到10万元的八个等级，在销售的商品内容中，珠宝玉石这样的非标商品占到了一定比例，高客单价可以保证有足够的利润空间。不过，王盛对这样的转型不太乐观，“秀场大部分的用户是男性，而男性群体本身的线上消费能力比较弱，女主播也没有像罗永浩那样的品牌效应，能吸引男粉丝去买一些高客单价的产品”。说起带货，孙毅鹏想到的场景是，女主播花言巧语哄着土豪老板们每人买几千件商品，这明显很难实现。淘宝、抖音、快手无一不是数亿月活和日活的大平台，但如果让3000万月活的映客去做直播带货，效果可想而知。“各方面都不具备直播带货的条件，包括供应链、销售系统、物流、服务体系等，本质上这是两套系统”，张默说。整体来看，秀场直播和带货直播的消费逻辑完全不同，目前还没有一种很好的结合方式，奔着买东西的话，秀场直播完全不是一个好选择。陌陌、YY们还能将人性生意持续做下去，但对于一家上市公司来说，还需要新的故事。*题图来源于视觉中国。应受访者要求，张默为化名。',
 'publish_time': '2020-06-30 08:58:00',
 'title': '秀场直播，成了“前浪”',
 'url': 'http://baijiahao.baidu.com/s?id=1670883546900821885'}
2020-06-30 19:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670888789448707638>
{'content': '来源：新浪科技新浪科技讯6月30日上午消息，继昨日晚间在微博回应被中消协点名一事之后，罗永浩今天继续在个人的微信公众号上再次针对这一情况进行说明，他表示，这是媒体标题党误导舆论，不过他很感谢中消协的监督，也会保障消费者的合法利益。罗永浩表示，中消协官网给出的报告描述属实，非常客观。针对和花点时间的合作，已经在此前给出了补救的措施。而价格全网最低的宣传，罗永浩认为他们在直播前都和厂商签订了协议，确保价格在直播期间是全网最低的，但部分平台和经销商会为了制造噱头压低价格，这些是无法控制的。他认为，竞相压价最终受益的是消费者，自己的团队也会竭尽全力保护消费者的合法权益。最后罗永浩还呼吁电商直播还处于起步阶段，需要更多的规范和监督，变得更加职业化。昨日（6月29日），中消协发布《“618”消费维权舆情分析报告》（下称《报告》），点名批评直播带货负面典型锤子科技CEO罗永浩，提及此前两次鲜花保鲜翻车事件，部分产品不符合“全网最低价”。',
 'publish_time': '2020-06-30 10:17:00',
 'title': '罗永浩回应被中消协点名：感谢监督竭力保护消费者权益',
 'url': 'http://baijiahao.baidu.com/s?id=1670888789448707638'}
2020-06-30 19:58:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670837916735264307> (referer: http://news.baidu.com/)
2020-06-30 19:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670837916735264307>
{'content': '文/刘喵喵编辑/水笙黄章退出魅族的消息又一次传出。6月26日，有媒体报道称，天眼查数据显示，持股49.08%的魅族创始人黄章（原名：黄秀章），近日退出珠海市魅族科技有限公司股东之列。但对此，魅族很快回应称，魅族没有任何股东信息的变更，后续会要求相关企查系统修正其出错信息。近几年，有关黄章淡出魅族的传闻已经出现多次，在魅族之外，大概很少人会把一家公司的创始人“退出”，当做开启新时代的序幕。黄章曾经几度隐退，又几度出山，他与魅族已经紧紧捆绑在一起，国内手机厂商竞争日益激烈的当下，魅族已经很久没有推出一款能够引起大众注意的新机了。今年5月发布的魅族17被寄托众望，但却依然没有起色，有粉丝评价那场发布会手机发布会几乎无人关注，线下门店也难觅踪影，魅族快被手机圈遗忘。一直以来，魅族始终无法摆脱“小厂”的命运，定位摇摆，战略失误，如今魅族面前的岔路口，有些像曾经的锤子手机，罗永浩最终出走，字节跳动的接手为锤子续了命。但是黄章会轻易认输吗？魅族最终的结局又将会是怎样？先行者却掉队了1976年，黄章出生于广东梅州，不同于小米创始人雷军、华为创始人任正非，黄章高一时被学校开除，没有上过大学，独自到深圳闯荡，在进入电子行业之前，曾经还做过码头搬运工。魅族的故事在2003年开始，这一年黄章一手成立的魅族，发布了第一款MP3随身听产品，而后推出的musiccard、miniplayer系列产品成为了销量冠军，创造了年销售额超过10亿的历史。但魅族做了中国第一台全触摸屏的手机，2009年，在黄章的带领下，首款魅族手机M8开售，两个月内销量达到10万部，五个月内销售额突破5亿元，这在当时是一份耀眼的成绩。2011年，魅族发布了第二款手机M9，开启了国产定制OS的大门，也开启了中国智能手机的拓荒之路。据不完全统计，从2003年到2009年，黄章发布了近6000个贴子。在黄章的要求下，魅族的很多员工都需要去及时了解用户反馈的信息。这一点被雷军“学习”了去，后来有关雷军成立小米的一段传闻是：雷军曾有意投资魅族，还将时任中国工程研究院副院长的林斌介绍给黄章，希望黄章能拿5%的股份来吸引林斌加盟，但黄章因为不忍股份被瓜分，拒绝了这个提议。在黄章的带领下，魅族站在了聚光灯下，成为了一家有潜力成为大厂商的公司。2010年是魅族光辉历史的顶点，如今回顾起来，也是走向衰落的开始，这一年，黄章决定隐退，两年后，小米诞生了。2012年，小米出货量达到719万台，魅族为100多万台；2013年小米的目标为2000万的时候，魅族手机的出货总量仅为200万台。2014至2015年，机海战术开启，魅族先后成立了子品牌魅蓝和魅族Pro，主攻年轻人群和高端市场。但在其他厂商抛弃这一策略，主攻精品的时候，魅族却没能完成转型，上千家门店开始成为累赘，魅族Pro7因为故障和Bug成为被消费者诟病的对象。这时候，被寄予救世主厚望的黄章，宣布复出。根据第三方调研机构赛诺公布的数据显示，2018年1月~11月，魅族品牌整体出货量为907万台，其中11月份仅47万台，同比下滑65%。相比2017年近2000万台的销量，几乎腰斩。两年过去，这一下滑的状况并没有得以扭转。IDC发布的2020年一季度中国智能手机出货报告显示，华为以42.6%的市场份额排名第一，vivo（18.1%）、OPPO（17.8%）分列二、三位。小米以10.6%的份额位列第四，苹果第五，份额为7.6%。魅族掉队了，这家起步较早的手机厂商，曾经赶上了时代的际遇，及时转型做智能手机，开启了国内智能手机市场的混战，遗憾的是，却没能在这场战争中胜出。定位摇摆探究一家公司走向衰落的原因有很多种，若归结魅族掉队的原因，从魅族Pro7的败北开始，魅族似乎就开始摸不准智能手机的发展方向。在智能手机厂商开始做全面屏手机的时候，魅族想做双屏幕手机；在小米6和荣耀10占据主流的2500元价位机型的时候，魅族推出魅族15，定位2499元，配置落后，几度回归的黄章，在对待魅族的策略上摇摆不定。2015年，小米是行业内的新星，学习小米之后，魅族又开始模仿起OPPO和vivo，以机海战术来争夺线下市场，开拓千家线下门店，频繁开发布会，还从vivo挖来了一位产品总监，负责魅族2016年的产品规划。2017年，这个模仿对象变成了华为，在魅族高级副总裁杨柘主导下，魅族的定位转变为高端机，魅族Pro7价格为2880起，Pro7Plus价格为3580起，但其相对较高的价格却没有打造出相应的产品，Bug问题频频被用户投诉。“梦想机”是黄章的希望，在他看来，只有打磨好一款好产品，才能让魅族重新拉回正轨，但是“梦想机”没能完成这个梦想。产品定位摇摆之外，管理问题也是魅族的困境，魅族没能留下人，也没能用好人。2019年7月18日下午，魅族科技首席营销官、高级副总裁李楠在社交网络上发文确认已离开魅族，“实际上魅族16发布会后，就慢慢淡出了工作。后面看到成功发布了数款产品，很欣慰。”李楠提到。至此，魅族“三剑客”白永祥、杨颜、李楠均已卸任。三剑客的加入和离开，伴随着黄章的隐退和出山。2010年黄章淡出公司日常管理，把公司交给曾经的“战友”白永祥，白永祥迎来了他的新头衔——魅族CEO。在黄章淡出的时期，公司加入了另外两位重要人物：杨颜和李楠。而后小米崛起，国内智能手机厂商开启白热化竞争，魅族周围群狼四伏。2014年年初，黄章出山，重新出任CEO一职。黄章回归后，白永祥职务接连变更了数次，从魅族CEO到高级副总裁，再到魅族总裁，黄章重出一线之后，白永祥事实上也开始一步步淡出魅族。2014年，魅族Flyme团队负责人空缺，杨颜补位，此后他一路高升，从升任副总裁，接手原本由李楠负责的配件事业部，职权越来越大。2015年，魅族刚有起色，黄章又一次淡出了公众视线，而两年后的2017年年初，黄章在魅族社区发声“感谢大家，我将重新出山打造我的梦想机，去迎接魅族15周年”，宣布再次复出。复出之后的黄章开始大刀阔斧地进行多次组织架构的调整。2018年5月，原本的魅蓝事业部和魅族事业部重新合并，杨柘继续担任CMO负责公司营销战略，李楠担任CSO，负责销售事业并向黄章汇报，白永祥卸任COO，由原CFO戚为民兼任，后传出白永祥已经辞职魅族。李楠在魅族待了7年，但是在黄章进行的多次组织架构调整当中，魅蓝和李楠的权重其实都在下降。魅族架构调整之后，魅蓝和魅族分开，魅族的营销交给杨柘，李楠只负责魅蓝。李楠想要押注魅蓝E3，但却一直处在缺货状态，据pingwest报道，在供应链上，魅族的需求被排在了魅蓝之上。李楠的出走或许也并不意外。失去了核心高管的魅族，还在失去更多。魅族会是下一个锤子吗？魅族和锤子曾经不常被拿来比较，但如今来看，两者可能会是相似的命运。从履历上看的话，黄章高一辍学，罗永浩高二辍学，两位都没有上过大学就开始创业，他们有着相似的经历。魅族和锤子也都曾经被追捧一时，被寄予厚望。创始人的性格在特定的时代背景下能够成就一家公司，但随着时间与行业发展的变化，也可能会成为阻碍一家公司发展的牢笼。成也萧何，败也萧何，用来形容老罗和黄章再不为过，但是如今老罗已经成了带货主播，而高傲的黄章将把魅族带往何处？未来，魅族想要改变命运，一方面需要找到新的资金支持，2015年，阿里投资魅族5.9亿美元。2018年底，阿里续投魅族的消息频繁传出，但目前来看，阿里也很难再继续给魅族续命。曾经，阿里希望在魅族手机上搭载阿里YunOS操作系统，但YunOS已经被魅族放弃，阿里再继续投资已经没有战略价值。魅族能否自救的关键，一方面在于产品能否跟上时代，另一方面在于能否完善供应链。2018年魅族发布的魅族16就是一个例子，这款机型被称为魅族当年做的最好的一款手机，创新性的上下对称设计的全面屏，相对高的配置和较低的价格，为魅族赢回了一波好评，产能不足直接导致销量的下滑，据赛诺数据显示，2018年1~11月魅族销售量仅为907万台，创历史最低，而魅族从2015年至2017年每年的出货量都在2000万台左右。想要靠产品翻身，需要充足的资金支持研发和供应链。魅族在减少成本，其人员在缩减，根据2019年度最新企业报告，其6月10日提交的报告申报员工人数为949人，去年同期为1694人，比去年下降745人。这一点与困境时期的锤子手机有着相似之处，几经裁员，缩减成本，锤子手机缺货的情况也一直没能改善，因此在手机行业，很难做成“小而美”，最终要么被收购，要么走向衰落。在黄章2019年发布的新年贺词上，黄章称做好了过冬的准备，并已经及时调整了组织规模，精简了产品线。展望未来，手机行业前景依然广阔。魅族将补齐营销短板，布局5G、IOHT(健康运动物联网)战略，将加强与阿里生态链的连接，并引入国资委等混合股权，进一步充实公司的资源力量。去年5月，珠海国资旗下虹华基金，完成了对魅族的注资，拥有2.09%的魅族股份，这一定程度上缓解了魅族的资金困境。但魅族如今想要重回主流已经很难，如果黄章再次淡出，魅族会更好吗？谁又是合适的带领魅族翻盘的人选？',
 'publish_time': '2020-06-29 20:53:00',
 'title': '黄章“退出”魅族，为什么是众望所归？',
 'url': 'http://baijiahao.baidu.com/s?id=1670837916735264307'}
2020-06-30 19:58:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9749235050767582862%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
2020-06-30 19:58:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670822658289037179> (referer: http://news.baidu.com/)
2020-06-30 19:58:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9749235050767582862%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670822658289037179>
{'content': '文/吴毓桢外媒BusinessInsider在25日报道称，大量泄露的特斯拉邮件显示，其在2012年就知道ModelS因电池设计不当，可能会导致短路甚至起火，但特斯拉官方仍将可能带有安全隐患的车辆，如期交付给了用户。图源BusinessInsider自家邮件被泄露，特斯拉早知道电池有隐患泄露邮件中，主要内容是特斯拉在制造ModelS车期间，曾经委托三家专业测试公司对车辆冷却系统进行测试，给出的三份结果均显示电池末端存在问题，在电池内部出现了电解液泄漏。IRM实验室在2012年的7月份曾通知特斯拉公司，末端连接配件铝制材料强度不过关，将有可能导致破裂泄漏电解液，但特斯拉官方并未理会，继续将生产好的ModelS轿车出厂交付用户。在当年第三季度，特斯拉合计交付ModelS车辆250余部。问题不止出现在车辆电池上，还有其他泄露邮件显示，2012年内，特斯拉工厂在生产过程中，在许多环节出现线圈泄漏和液体泄漏的问题。多次问题的出现并没有引起特斯拉官方的重视，带“病”的电车还是被交付至路上行驶。车辆频频自燃，究竟是为何？自打国内一线城市限制汽油车上牌以后，国内外车企都疯狂研发电动汽车，从造车厂到充电桩，一系列与电车有关的产品都在市面快速普及。马路上挂着绿牌的电车也越来越多，但是随之而来的电车自燃爆炸新闻也是接二连三。自特斯拉于2012年交付ModelS至今，国内外该车型自燃事件频繁发生。2019年3月26日，广州一小区地下停车场ModelS车辆发生自燃。同年4月21日上海一ModelS车辆在地库发生自燃，5月12日旧金山一ModelS车辆在路上停放时发生自燃。这只是特斯拉一品牌中的一款车型自燃事件，其他众多电车品牌汽车自燃新闻更是数不胜数。那么到底是什么问题，让代表着先进技术的新能源电车频频发生自燃爆炸事件？纵观电车自燃事件，多数发生在电车充电期间，行驶中发生自燃的几率比较小，电池内部的材料质量，电池部件老化，充电电压不稳定，电控系统性能差等等这一系列问题，都有可能导致电车在停放或者是遭遇碰撞时出现自燃爆炸。而在特斯拉本次“邮件门”的邮件内容中提到的电解液泄漏，也是可能导致车辆自燃的因素之一。引力新能源CEO徐曦告诉锌财经：“电解液泄露就会引起电池短路，烧坏电池线束，短路导致电池过热，然后最严重的情况就是电池爆燃引起车辆自燃。虽然这样的连锁反应发生概率较小，但是还是不排除会引发自燃的后果。”现售车辆安全性大胜从前，行业蓬勃发展仍需攻坚虽然电池产业发展历史不短，但各类电池厂商在车辆电池的领域的研发时间并不长。早期电池厂商们生产的电池质量参差不齐，许多电池用材低廉，并且在装配工艺上也远不及现在。电池厂商们也意识到生产的电池存在问题，所以不断加大投入。于是在全球市场便诞生了诸如宁德时代、比亚迪、LG化学等一流的电池供应厂商。相比早期的汽车电池，无论从续航、使用寿命、充电效率哪一方面来说，都有了巨大的进步。以特斯拉为首的厂家们也从电池结构用料与电控系统入手，不断提升车辆的安全性能。特斯拉现售车型都使用了密集电芯阵列的电池结构，核心目的就是为了避免少数电芯损坏时引起短路起火。“当一个电芯短路时，电池自检系统会发现，并迅速切断电流或者降速。特斯拉能够通过优秀的电控技术来及时发现电池隐患并处理，在电控技术上，国内车企还是存在一定差距。”徐曦说道。车辆电池产业的苦心研发，的确提升了现售电车的安全性。可要让整个电池系统做到真正完全安全却并不简单，从当前国内外电车品牌的拆解电池充电测试来看，就能发现其中的不足。普通小型家用电池的健康电池曲线应为平滑曲线，但大部分市面上的电车电池充电测试曲线都出现了不同程度的上下偏振。业内专家对此进行了解释，导致充电测试曲线出现偏振的原因，主要在于电池组本身、车载充电机、逆变器等等与充电系统有关的设备质量和适配问题上。当电车的需求市场日益庞大，光靠喊口号抢市场是不适用于电车厂商们了。不论各大品牌如何宣称自己的车辆有多安全，人命是无价的，只有真正降低事故率，市场才会予以认可。所以，钻研提升车辆安全性的脚步，永远不能停下。',
 'publish_time': '2020-06-29 16:50:00',
 'title': '特斯拉“邮件门”，揭秘自燃背后的真相',
 'url': 'http://baijiahao.baidu.com/s?id=1670822658289037179'}
2020-06-30 19:58:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670886845010647668> (referer: http://news.baidu.com/)
2020-06-30 19:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670886845010647668>
{'content': '艺术家描绘两个黑洞在一个超大质量黑洞的圆盘内合并，之后释放出一束光。',
 'publish_time': '2020-06-30 09:47:00',
 'title': '科学家探测到两个黑洞碰撞产生的闪光信号',
 'url': 'http://baijiahao.baidu.com/s?id=1670886845010647668'}
2020-06-30 19:58:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670839717334262371> (referer: http://news.baidu.com/)
2020-06-30 19:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670839717334262371>
{'content': 'PingWest品玩6月29日讯，TCL电子今天宣布，以人民币15亿元，收购TCL实业全资附属公司TCL通讯100%股份。同时，TCL电子将所持有的茂佳国际100%股份作价人民币25亿元向TCL实业出售，TCL实业将以现金方式支付。扣除收购代价后，公司将获得出售所得款净额约人民币10亿元，将主要用于进一步提升TCL品牌业务市场份额、加大AIxIoT研发投入、扩大互联网增值服务收入，及重点布局智慧商用显示。',
 'publish_time': '2020-06-29 21:22:00',
 'title': 'TCL电子拟收购TCL通讯100%股份',
 'url': 'http://baijiahao.baidu.com/s?id=1670839717334262371'}
2020-06-30 19:58:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9064943818564688854%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
2020-06-30 19:58:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670880677240037132> (referer: http://news.baidu.com/)
2020-06-30 19:58:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9064943818564688854%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670880677240037132>
{'content': '来源：创事记欢迎关注“创事记”的微信订阅号：sinachuangshiji文/江瀚视野观察从互联网移动社交兴起至今，陌陌一直都是一个非常特殊的名字，如果你的朋友手机上装了一个陌陌或者陌陌旗下的探探，总会引发大家不怀好意的目光，然而就是这个陌陌却实现了互联网企业少有的连续盈利，但是为什么连续盈利的背后，陌陌却遭到了投资者的质疑，大家的问题其实都是一致的这就是陌陌的荷尔蒙颜值直播到底还能火多久呢？前不久互联网社交软件陌陌发布了属于自己的财报，2020年第一季度，陌陌获得了人民币5.37亿元的净利润，这已经是这家社交+直播公司连续第21个季度盈利了。相比其他在美、港股上市的大陆企业，连续盈利的陌陌堪称独树一帜。具体来看，2020年第一季度，陌陌净营收达35.941亿元，同比下降3.5%，其中直播服务营收23.32亿元，同比减少13%；增值业务营收达到11.758亿元，同比增长30%。营收规模虽然超华尔街预期，但受疫情影响，公司收入历史首次出现负增长。据悉，陌陌成立于2011年，是我国第一款陌生人社交软件，以“附近的人”为主要功能提供的线上社交俘获了大批用户的心，特别是男性用户。公司成立之初便获得了经纬创投和紫辉创投的250万美元天使轮融资，投后估值达1000万美金。此后，公司每年都有完成大额融资，并顺利在2014年登陆纳斯达克，成为了“陌生人社交第一股”。然而，互联网上却是质疑之声一片，其中最旗帜鲜明的无疑是互联网媒体钛媒体了，钛媒体表示三个核心数据显示陌陌正在由盛转衰：一是净营收下滑。Q1陌陌净营收达35.941亿元，尽管高于公司之前给出的业绩指引上限35.5亿元，但仍同比下降3.5%，这是其净营收历史首次出现下滑。二是月活下滑。从2018年Q4开始，陌陌就已出现月活增长乏力的苗头，去年增速放缓迹象愈发明显，四个季度增速分别为10.75%、5.09%、3.26%、1.06%。今年Q1更是演变为比增长停滞更可怕的局面，月活首次出现负增长，同比下滑5.59%至1.08亿，跌回至2018年Q2水平。三是付费用户下滑。直播业务、增值服务是陌陌两大主要营收来源，各自付费用户数量的多寡直接决定陌陌净营收的高低。Q1陌陌直播服务与增值服务付费用户去重后总数达1280万（包括探探付费用户420万），同比减少8.6%，即120万，这是其近两年来付费用户首次出现负增长。钛媒体认为陌陌只要有一个数据有问题就已经是值得高度警惕的信号了，更何况是连续三个数据，而且表示类似态度的不止钛媒体，老虎证券、创业i黑马、投中网等等几乎集体给陌陌投了不信任票，那么，陌陌到底怎么回事？这个原本最赚钱的陌生人社交，主打荷尔蒙的颜值直播为啥都不能吸引人了？二、陌陌为啥不能吸引人了？我们纵观陌陌的发展历程就会发现，这家公司成立的很早，2011年是微信刚刚出现不久的日子，甚至是人人网这个实名制熟人社交还很红火的时代，在这个时期陌陌就已经出现了，主打陌生人社交的模式让陌陌在短时间内迅速火了起来，这种快速红火的陌陌虽然在其中有着很多让人觉得暧昧甚至擦边球的成分，但是也的确要承认，这种陌生人的模式是整个市场最受欢迎的模式之一，其实全球互联网最火的流量来源都是类似的网站，陌陌红火也是意料之中的事情，就这样在这一片质疑声中，陌陌跌跌撞撞走了出来，2018年，陌陌发布公告称拟以500万A类股票和6亿美元现金，收购探探100%股权。陌生人社交软件第一梯队的企业合并，同时也是业内迄今为止最大的并购案，备受瞩目。宣布收购当天，陌陌股价涨逾17%，这一段时间可谓是陌陌的高光时刻。而与陌陌的产业高光不同，陌陌转型直播始于2015年，可谓是抓住了市场的又一大风口，从陌生人社交平台逐渐转变成带有陌生人社交性质的直播产品，陌陌实现了从无到有的跨越，直播更是顺理成章成为了陌陌最赚钱的业务，如今陌陌的整体营收都高度依赖于直播业务，本来2020年大家都被家里蹲，直播本应该是最红火的产业，其他直播企业都靠着井喷的流量赚的盆满钵满，反而陌陌却出现了负增长，这让所有人都觉得有些出乎意料，这其中的原因到底是什么？首先，荷尔蒙式的颜值直播可能并不适合现在。仔细研究陌陌的直播模式，陌陌并不是现在流行的那种直播带货式的直播模式，陌陌的直播模式比较特殊，我们可以称之为荷尔蒙式的颜值直播，打开陌陌的直播就会发现其直播模式是比较明确的“高颜值直播”，直播间的主播几乎都是俊男靓女，再结合一下陌陌本身的陌生人社交模式就很明确的知道，为什么陌陌是这种“荷尔蒙式的颜值直播”，毕竟大多数人来陌陌的目的都或多或少有这样的成分在里面，自然陌陌也就只能依靠这样的直播模式。但是，这种直播有个显著的缺点，就是这种偏娱乐化的直播其营收严重依赖于“土豪粉丝”的打赏，由于在经济条件好的时候，“土豪粉丝们”往往会一掷千金，平台拿到的打赏分成更高，一般是30%-60%，这种高营收模式让平台形成了路径依赖，所以在当前经济条件不好，土豪们打赏意愿明显不足的时候，陌陌之前赚快钱的模式让其显得完全无招架之力。其次，陌生人社交已经成为了群雄逐鹿的红海。当然，陌陌出现问题还有一个非常重要的原因，这就是陌生人社交已经不是当年的蓝海，虽然陌陌在收购了探探之后取得了当之无愧的市场霸主地位，但是正所谓风水轮流转，在熟人社交已经被微信牢牢把控的时候，陌生人社交就成了各大互联网巨头相互角力的主战场，而陌陌虽然有着市场的先发优势，却不一定是这些互联网巨头们的对手，数据显示，陌生人社交领域目前有874家公司，其中大多数成立于2014年和2015年，占比分别是26.9%和16.8%。而很多巨头也已经深度进入了这个市场，比如，阿里的“real如我”、“唱鸭”、“古桃”等9款社交产品；腾讯的轻聊跟回音；百度的听筒；字节跳动的多闪等。当然，互联网的对手永远不是来自于行业内部，对于陌陌来说这种陌生人的社交其实正在被短视频所打破，特别是两大巨头，抖音、快手也都在布局直播领域，名人效应让“抖快”的直播名声大噪，比如郑爽在快手做的入职直播，网易CEO丁磊在快手的直播都吸引了大批粉丝观看，这个时候陌陌可以说面临着巨大的竞争与挑战。第三，陌陌真的没有希望了吗？我们客观地说，陌陌的希望还是有的，我们之前就曾经说过陌陌已经连续21个季度盈利了，这在中国互联网公司中实际上是不多的，财报中陌陌披露，在连续21个季度的盈利后，它已经积累了大约20亿美元的现金，根据上市公司的玩法，陌陌仅仅依靠这么多现金的投资陌陌就可以足够赚利息了，Q1陌陌光利息就赚了1.3亿，不过这也体现出来陌陌的资金利用效率并不好，这么多的现金却没能用到它该用的地方去，这无疑是陌陌最大的问题所在。不过，我们也没必要过分唱衰陌陌，毕竟陌陌的负增长并不意味着全线的崩溃，但是在这个直播+的时代，无论是带货还是教育或者云健身，都是需要不断开拓市场边界的，在这方面陌陌无疑就差了很多。主打荷尔蒙颜值直播的陌陌面对着当前的困局，是时候要改变了，这个时代灵活应变才是最大的时代发展趋势，不知道有些略显迟缓的陌陌看懂了吗？',
 'publish_time': '2020-06-30 08:01:00',
 'title': '陌陌连续盈利却首现负增长，荷尔蒙颜值直播还能火多久？',
 'url': 'http://baijiahao.baidu.com/s?id=1670880677240037132'}
2020-06-30 19:58:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670850362569959688> (referer: http://news.baidu.com/)
2020-06-30 19:58:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10200249759946127924%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
2020-06-30 19:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670850362569959688>
{'content': '资料图。中新社记者陈骥旻摄资料图：主播在店铺内通过线上直播销售商品。中新社记者韩苏原摄资料图：主播在“吃播”。图片来源：淘宝直播资料图：一位工人直播包“辣条馅”的饺子。中新社记者杨华峰摄',
 'publish_time': '2020-06-30 00:05:00',
 'title': '首个直播带货规范7月施行刷单、杀雏等乱象或得整治',
 'url': 'http://baijiahao.baidu.com/s?id=1670850362569959688'}
2020-06-30 19:58:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10200249759946127924%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670879868520929992> (referer: http://news.baidu.com/)
2020-06-30 19:58:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9726526330209462607%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
2020-06-30 19:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670879868520929992>
{'content': '出品｜虎嗅大商业组作者｜敲敲格题图｜ICPhoto疫情的到来让所有零售商低下头颅——全世界最强悍、最有知名度的运动品牌也不例外。当地时间6月26日，世界最知名运动品牌之一的耐克发布其2020财年第四季度的财报（截止2020年5月31日的三个月），该季度营收为63.1亿美元，同比下降38%，远低于市场预期（73.8亿美元）；平均每股亏损51美分，同样远低于市场预期（每股盈利10美分）。虽然市场对于疫情背景下各企业的业绩预期都比较低，但耐克受到的打击还是远比想象中大——单季净亏损为7.9亿美元（即超过50亿元人民币），而去年同期的净利润为9.89亿美元。对于这样惨淡的业绩，耐克在财报中解释为，受疫情影响，除大中华区外的大部分耐克自营与经销商门店都在Q4处于关闭状态，大概有90%的门店都关闭了八周以上。此外，由于订单取消，产品的出货量在本季度下滑约50%，这也导致耐克的营收下降、库存上升。在这样恶劣的情况下，“活下去”成为首要目标。据Complex杂志报道，耐克CEO约翰·多纳霍（JohnDonahoe）在给员工的邮件中宣布耐克将开启裁员。但他表示，裁员并不是因为节约开支，而是由于公司将进行内部资源重组、重新投入公司最具增长潜力的领域，预计这样的内部重组将导致裁员。此外，他还表示，目前“还不确定裁员将波及多少个工作岗位，也不确定谁将受到具体影响。”大中华区很好，但不够在这份情况惨烈的Q4季报发布前，耐克交过一份超预期的Q3财报。2020财年Q3（截止今年2月29日的三个月），耐克实现营收101.04亿美元，同比增长5%，虽然净利润等指标有所下滑，但仍超出华尔街预期。在这个季度，大中华区受疫情冲击严重，而随着疫情在全球范围内的爆发，较早恢复销售的大中华区成为了增长主力。耐克的全球销售划分为四个大区：北美、大中华区、EMEA（欧洲、中东和非洲地区）与APLA（亚太和拉美地区）。在Q4财报中，耐克提到，由于北美等三个大区的大部分实体门店关闭，抵消了大中华区的增长。Q4，大中华区实现营收16.47亿美元，同比增长1%（汇率不变）；在整个2020财年，大中华区营收为66.79亿美元，同比增长11%，这是耐克的大中华区连续六年实现了双位数增长。2015年，耐克首次提出DirectToCustomer（直面消费者，以下简称DTC）战略，开始看重线上的销售与创新、注重用户的个性定制等等，总而言之，就是以用户为核心，尤其看重线上用户数据的应用：追踪消费习惯、分析消费偏好、提供更“个性化”的服务，进而建立品牌与用户更深的联系。在大中华区，耐克在线上先后布局了Nike.com、独家鞋款抽签发售平台SNKRS、天猫旗舰店、“Nike耐克”微信小程序、跑步和训练的应用程序NTC、NRC等等。2019年底，NikeApp中文版终于上线，在这个App里，耐克更强调对会员的服务，同时它也是耐克大中华区线上直营零售的核心平台。在2020财年Q1的财报中，耐克提出公司的目标是在2023年实现数字化业务营收占总营收比例达到30%。到了Q4，耐克的数字化业务营收同比增长79%，占公司总收入的30%，已经提前3年完成了目标；放眼整个财年，尽管后半年受疫情影响严重，但数字业务还是实现了49%的同比增长。开启库存清除计划除了发力线上渠道销售，耐克在数字化方面的努力还体现在对“技术”的不断追求，尤其爱收购技术类公司。上述所有收购都指向同一个DTC目标——进一步挖掘用户消费数据，掌握用户的行为与喜好，最终提升库存管理水平。在完成对Celect的收购时，耐克首席运营官埃里克·斯普朗克（EricSprunk）在一个采访中表示，耐克将更加关注消费者的个体需求，重视数据——提前预测需求——改善库存，耐克在这个链条的每一环上都做了不少努力，库存水平确实也得到了实在的改善。从2015年到2019年，耐克的存货（Inventories）以同比5%~8%的增速在逐渐增加，但存货周转率（InventoryTurns）始终保持在4左右，即每季度一次。截止5月31日，耐克的库存达到73.7亿美元，同比增长31%，比去年同期增长超17亿美元——和前几年不超过10%的增幅相比，耐克在今年的库存压力可想而知。如果你对运动品牌足够关注，应该能感受到今年618期间各大运动品牌打折力度之强劲：耐克、阿迪达斯等定价较高的品牌打折后的价格直接“降档”，进入原先中国李宁、安踏等品牌的价格档位；安踏、李宁在打折后价格继续向下、与低价品牌抢用户。为摆脱沉重的库存，各个品牌都开启了“降维打击”。巨亏的耐克仍旧能掌握行业主动权，而那些零散的小品牌、下游的经销商，或许正承受着更令人窒息的压力。',
 'publish_time': '2020-06-30 07:00:00',
 'title': '浓眉大眼的耐克也开始裁员了',
 'url': 'http://baijiahao.baidu.com/s?id=1670879868520929992'}
2020-06-30 19:58:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670883015949925680> (referer: http://news.baidu.com/)
2020-06-30 19:58:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9726526330209462607%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670883015949925680>
{'content': '房东陈先生供图来源：黑猫投诉平台',
 'publish_time': '2020-06-30 08:44:00',
 'title': '左手压价房东、右手涨价租客自如为何如此霸道｜诉说',
 'url': 'http://baijiahao.baidu.com/s?id=1670883015949925680'}
2020-06-30 19:58:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://baijiahao.baidu.com/s?id=1670883015973794080> (referer: http://news.baidu.com/)
2020-06-30 19:58:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9615711337831643695%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
2020-06-30 19:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://baijiahao.baidu.com/s?id=1670883015973794080>
{'content': '本报驻美国、新加坡特约记者吴倩辛斌本报记者张旺瑞幸咖啡29日在美国纳斯达克停牌，并进行退市备案。这个成立19个月便火速上市的“小蓝杯”，最终创下了上市13个月便退市的纪录。虽然瑞幸终结了“纳斯达克之旅”，但是由此引发的余波并未停息，各方都在反思瑞幸给中国企业乃至美国股市带来的深刻教训。29日，《环球时报》记者在北京朝阳区一家瑞幸咖啡店看到，店员正在忙碌，吧台上摆满了打包好准备外送的外卖。有店员告诉记者，虽然退市，但她所在的这家门店没听说要撤，“店里生意没受影响”。此前，瑞幸咖啡表示，将在6月29日美股开盘时停牌，但全国4000多家门店将正常运营。美国《华尔街日报》29日称，瑞幸咖啡股价上周五暴跌54%，至1.38美元，市值降至约3.5亿美元。今年早些时候发售股票后不久，其市值曾触及120亿美元的高点。尽管瑞幸退市并未对其现有门店的经营造成明显影响，但香港星岛环球网报道说，摘牌退市等来自资本市场的处罚只是一个开端，瑞幸或将面临后果更为严重的处罚与巨额赔偿。香港法院已下令冻结瑞幸在开曼群岛和香港地区的资产，限制其对开曼群岛及香港注册实体下的资产进行出售或转移。若以2020年初至今作为时间段计算，粗略估算，面临集体诉讼的瑞幸将遭遇总计约112亿美元赔偿。瑞幸公司从收到通知到最终被摘牌，退市流程可能会持续几个月至半年。武汉科技大学金融证券研究所所长董登新29日对《环球时报》记者表示，按照常规来说，瑞幸从纳斯达克摘牌之后可能会转板到“粉单市场”。“粉单市场”是美国专门接纳退市企业的场所，那里的股价很多也就几美分，交易很清淡，鲜有人问津。退市企业的股东或投资者可以在“粉单市场”转手自己手里股票，要想卖出去就得主动大幅降价。“瑞幸如果还想继续发展，那就要通过瑞幸自己或者非瑞幸的大股东，在‘粉单市场’上收购所有股份，切断与美国投资者关系，然后回国寻找投资者，改制再图发展。”董登新表示，如果瑞幸觉得自己干不下去了，大股东也没有信心，那么瑞幸只能向法院申请破产，美国股东和投资者就需要参与瓜分瑞幸破产清算的剩余资产当中。“但由于瑞幸属于轻资产企业，二手咖啡机也卖不了多少钱”。瑞幸造假事件也触发中概股信任危机。香港《南华早报》29日称，2018年，美国监管机构表示，它在对224家上市公司“检查主要审计师的工作时遇到障碍”。其中有213家是中国公司。今年4月，瑞幸咖啡成为最新的例子。美国国会参议院上月20日通过《外国公司问责法案》，目前等待众议院投票。根据该法案，连续3年不提供信息将导致股票被禁止交易。全面的立法可能会将上市的中国公司从美国证券交易所除名。中国企业正以2015年以来最快的速度退出美国股市。美国彭博社报道称，数据显示，今年迄今，在美国上市的中国企业已经宣布四宗私有化退市交易，包括债务在内的总价值为81亿美元。而去年和前年同期则几乎为零。《南华早报》称，随着中国企业向其他国家寻求资本，《外国公司问责法案》有可能拖累美国国内企业和投资者，成为意外的受害者。如果中国企业开始离开美国证交所，股东将受到影响，因为蒸发的交易量将拖累股价。美中贸易全国委员会政府事务高级主管安娜·阿什顿认为，《外国公司问责法案》是美国在应对中国方式欠考虑的又一个例证。泛大西洋投资集团首席执行官比尔·福特表示:“我担心(该法案)将对在美国上市的中国企业产生‘寒蝉效应’。”《南华早报》称，阿里巴巴、京东和网易在香港二次上市都是最近进行的，表明中国企业的思维发生变化。传统上，中国企业为了声望和流动性而青睐美国证交所。纽约资产管理经理森普尔表示，对于大型中企来说，从美国证交所退市将意味着“一组投资者实际上被另一组投资者所取代”。董登新认为，现在有200多家中概股在美国上市，占外国公司在美股挂牌总量的1/3。中国现在有了沪港通和深港通，中概股将来如果从美国摘牌，无论回归港交所，还是回到内地，对外国投资者影响都不会特别大。但是中概股从美国撤出，对美国股市影响会比较大。阿里巴巴、京东、拼多多等市值都较大，都撤走的话对美国股市的国际性会造成影响。而且中概股大多数都是互联网、新经济概念企业，对美股人气方面也会有折损。但董登新也表示，瑞幸因造假丑闻退市，对所有中企都是一个严重警告，无论在国内外何处上市，都必须守法，否则就会被投资者抛弃，受到惩处。面对美国的打压，中概股如被要求退市，董登新建议，不要主动在目前的股市上高价回购股本，因为按照美国股市收购规则，一般要溢价30%左右，这样成本会很高。“从美股退市后，好的企业依然会受到港股和A股的追捧”。▲',
 'publish_time': '2020-06-30 08:44:00',
 'title': '瑞幸退市留下一堆问号：能否东山再起如何应对赔偿',
 'url': 'http://baijiahao.baidu.com/s?id=1670883015973794080'}
2020-06-30 19:58:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9615711337831643695%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10585666853574458721%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
2020-06-30 19:58:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9856425872335171303%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
2020-06-30 19:58:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10585666853574458721%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9856425872335171303%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9989489955052130071%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
2020-06-30 19:58:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9778491685034028513%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
2020-06-30 19:58:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9989489955052130071%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9778491685034028513%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670852409110574829)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10021869434221085478%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
2020-06-30 19:58:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10021869434221085478%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10028718433968169981%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
2020-06-30 19:58:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10028718433968169981%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9150879229378473252%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
2020-06-30 19:58:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9150879229378473252%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301325297.html> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
2020-06-30 19:58:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301325708.html> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
2020-06-30 19:58:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9701664460995839863%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900922521341165)
2020-06-30 19:58:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301325297.html> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301325708.html> (referer: http://baijiahao.baidu.com/s?id=1670914908167595360)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9701664460995839863%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900922521341165)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10147644815787186589%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
2020-06-30 19:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10147644815787186589%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9615879700498161835%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
2020-06-30 19:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9615879700498161835%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9540035457095714716%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
2020-06-30 19:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9540035457095714716%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9551264782277022942%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
2020-06-30 19:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9551264782277022942%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10682666680010433848%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
2020-06-30 19:58:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.thepaper.cn/baijiahao_8055625> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9673550283776217419%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10682666680010433848%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9443788096130730512%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
2020-06-30 19:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9443788096130730512%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10252264626997518129%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
2020-06-30 19:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10252264626997518129%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10165387467370556790%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
2020-06-30 19:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10165387467370556790%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9308176681401257554%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670837916735264307)
2020-06-30 19:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9308176681401257554%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670837916735264307)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10131940697293423556%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670822658289037179)
2020-06-30 19:58:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9797966982324300622%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670837916735264307)
2020-06-30 19:58:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10131940697293423556%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670822658289037179)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8950956589062928264%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
2020-06-30 19:58:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9797966982324300622%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670837916735264307)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8950956589062928264%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9675366006905761464%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
2020-06-30 19:58:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9675366006905761464%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:47 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301325824.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9746245512972872143%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9605977258284379582%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670880677240037132)
2020-06-30 19:58:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9605977258284379582%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670880677240037132)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9552128276934076403%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670880677240037132)
2020-06-30 19:58:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9552128276934076403%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670880677240037132)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301327916.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9220240511626316401%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10083084563793299790%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
2020-06-30 19:58:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10083084563793299790%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301328115.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9658296015981642268%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10266122575262803308%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
2020-06-30 19:58:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301326819.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10387948420610317996%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10266122575262803308%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10286178521950094443%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015973794080)
2020-06-30 19:58:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301325664.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10120502430534214149%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10286178521950094443%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015973794080)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9788052449701444702%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015973794080)
2020-06-30 19:58:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9788052449701444702%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015973794080)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9775745783566230828%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
2020-06-30 19:58:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9775745783566230828%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9516759298448078216%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
2020-06-30 19:58:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9516759298448078216%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10183691634412859977%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
2020-06-30 19:58:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10183691634412859977%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10201974610174567461%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
2020-06-30 19:58:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10201974610174567461%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301328059.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9495398588030209956%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10211043807314380437%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
2020-06-30 19:58:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10211043807314380437%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10161705911554153686%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
2020-06-30 19:58:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10161705911554153686%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9827380009303539057%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
2020-06-30 19:58:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9827380009303539057%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9891110318855735894%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
2020-06-30 19:58:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301328280.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9049282546637463202%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9891110318855735894%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9582552077227904319%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
2020-06-30 19:58:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9582552077227904319%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.thepaper.cn/baijiahao_8055625> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
2020-06-30 19:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10169310791145618571%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
2020-06-30 19:58:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.thepaper.cn/baijiahao_8055625> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9713062050111578176%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
2020-06-30 19:58:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10169310791145618571%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10075231052903891486%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
2020-06-30 19:58:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9713062050111578176%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10075231052903891486%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9004297115075371553%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670880677240037132)
2020-06-30 19:58:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9004297115075371553%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670880677240037132)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10875327578462805952%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670880677240037132)
2020-06-30 19:58:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10875327578462805952%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670880677240037132)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9354793663714400436%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
2020-06-30 19:58:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9354793663714400436%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9315244037183710052%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
2020-06-30 19:58:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9315244037183710052%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10069860608608964670%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
2020-06-30 19:58:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10069860608608964670%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10284130642950537285%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
2020-06-30 19:58:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301325824.html> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
2020-06-30 19:58:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10284130642950537285%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301325824.html> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9489248095898978140%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
2020-06-30 19:58:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9489248095898978140%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670839717334262371)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9739542254454085657%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
2020-06-30 19:58:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301327916.html> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
2020-06-30 19:58:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9739542254454085657%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301327916.html> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9660145939924975358%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
2020-06-30 19:58:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9660145939924975358%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301328115.html> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
2020-06-30 19:58:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301328115.html> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9451167515714122312%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
2020-06-30 19:58:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9451167515714122312%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301326819.html> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
2020-06-30 19:58:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301326819.html> (referer: http://baijiahao.baidu.com/s?id=1670883015949925680)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10275622231131033733%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
2020-06-30 19:58:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10275622231131033733%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670886845010647668)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301325664.html> (referer: http://baijiahao.baidu.com/s?id=1670883015973794080)
2020-06-30 19:58:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301325664.html> (referer: http://baijiahao.baidu.com/s?id=1670883015973794080)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10127573913828303142%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670822658289037179)
2020-06-30 19:58:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10127573913828303142%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670822658289037179)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9053778342397920304%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670822658289037179)
2020-06-30 19:58:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9053778342397920304%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670822658289037179)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9767159336633615460%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670837916735264307)
2020-06-30 19:58:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9467429000679823037%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670837916735264307)
2020-06-30 19:58:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9767159336633615460%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670837916735264307)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9467429000679823037%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670837916735264307)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9132759045801467737%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
2020-06-30 19:58:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9132759045801467737%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301328059.html> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
2020-06-30 19:58:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301328059.html> (referer: http://baijiahao.baidu.com/s?id=1670879868520929992)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9137758623827531257%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
2020-06-30 19:58:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9137758623827531257%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9986712704664744353%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
2020-06-30 19:58:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9986712704664744353%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301327778.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10153743076584407400%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9171366725903502046%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
2020-06-30 19:58:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9171366725903502046%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301328280.html> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
2020-06-30 19:58:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301328280.html> (referer: http://baijiahao.baidu.com/s?id=1670850362569959688)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9947866585154102284%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
2020-06-30 19:58:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9947866585154102284%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10017890649662689453%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
2020-06-30 19:58:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10017890649662689453%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9992388529638236264%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883546900821885)
2020-06-30 19:58:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10002412906114254353%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883546900821885)
2020-06-30 19:58:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9992388529638236264%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883546900821885)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10002412906114254353%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883546900821885)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://m.gmw.cn/baijia/2020-06/30/1301327235.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9874076332599829724%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9934578896796140442%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
2020-06-30 19:58:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9934578896796140442%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9143367198337948510%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
2020-06-30 19:58:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9143367198337948510%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9659510112934709121%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
2020-06-30 19:58:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9659510112934709121%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893713637541420)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9475802554796212895%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
2020-06-30 19:58:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9708940281660669750%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
2020-06-30 19:58:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9475802554796212895%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9708940281660669750%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10102819058049581768%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
2020-06-30 19:58:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10102819058049581768%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9716695661207611818%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
2020-06-30 19:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9716695661207611818%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670895742616004589)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9552364027639548104%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
2020-06-30 19:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9552364027639548104%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9701999928023115016%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
2020-06-30 19:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9701999928023115016%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sghservices.shobserver.com/html/baijiahao/2020/06/30/215226.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9067440826639341531%22%7D&n_type=1&p_from=4>
2020-06-30 19:58:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9812389448158786209%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
2020-06-30 19:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9812389448158786209%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:58:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9397107720129997269%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
2020-06-30 19:58:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9770067441611195886%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
2020-06-30 19:58:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9397107720129997269%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://export.shobserver.com/baijiahao/html/264350.html> from <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9702789265698853144%22%7D&n_type=1&p_from=4>
2020-06-30 19:59:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9770067441611195886%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9157009255730637574%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
2020-06-30 19:59:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9721918199647475798%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
2020-06-30 19:59:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9157009255730637574%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9721918199647475798%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10045699106848861051%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
2020-06-30 19:59:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10045699106848861051%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9973331373213768220%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
2020-06-30 19:59:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9973331373213768220%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9561496790277046143%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
2020-06-30 19:59:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9439973624022170334%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
2020-06-30 19:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9561496790277046143%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9439973624022170334%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9976002181453498561%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
2020-06-30 19:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9976002181453498561%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9470407496046618747%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
2020-06-30 19:59:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9093110437294407118%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
2020-06-30 19:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9470407496046618747%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9093110437294407118%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301327778.html> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
2020-06-30 19:59:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9389253547861360462%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
2020-06-30 19:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301327778.html> (referer: http://baijiahao.baidu.com/s?id=1670888789448707638)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9389253547861360462%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670883529085697077)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9739302290255362734%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
2020-06-30 19:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9739302290255362734%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9598207305988110001%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
2020-06-30 19:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9598207305988110001%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9727622770941207719%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
2020-06-30 19:59:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9727622770941207719%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10124934875350172054%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
2020-06-30 19:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_10124934875350172054%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9547106691239866173%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
2020-06-30 19:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9547106691239866173%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9675165728316076527%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
2020-06-30 19:59:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.gmw.cn/baijia/2020-06/30/1301327235.html> (referer: http://baijiahao.baidu.com/s?id=1670883546900821885)
2020-06-30 19:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9675165728316076527%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.gmw.cn/baijia/2020-06/30/1301327235.html> (referer: http://baijiahao.baidu.com/s?id=1670883546900821885)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9800337387638445301%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
2020-06-30 19:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9800337387638445301%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670842465572337534)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9469146257442553775%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900922521341165)
2020-06-30 19:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9469146257442553775%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670900922521341165)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9249775515610474840%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
2020-06-30 19:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9249775515610474840%22%7D&n_type=1&p_from=4> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9649102629759560066%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
2020-06-30 19:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8760724743616296310%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
2020-06-30 19:59:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_9649102629759560066%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8948144437774328208%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
2020-06-30 19:59:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8760724743616296310%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://mbd.baidu.com/newspage/data/landingsuper?context=%7B%22nid%22%3A%22news_8948144437774328208%22%7D&n_type=1&p_from=3> (referer: http://baijiahao.baidu.com/s?id=1670890939763251893)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sghservices.shobserver.com/html/baijiahao/2020/06/30/215226.html> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
2020-06-30 19:59:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sghservices.shobserver.com/html/baijiahao/2020/06/30/215226.html> (referer: http://baijiahao.baidu.com/s?id=1670893602283404530)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://export.shobserver.com/baijiahao/html/264350.html> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
2020-06-30 19:59:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://export.shobserver.com/baijiahao/html/264350.html> (referer: http://baijiahao.baidu.com/s?id=1670900695105270086)
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\defer.py", line 117, in iter_errback
    yield next(it)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\utils\python.py", line 345, in __next__
    return next(self.data)
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\middlewares.py", line 36, in process_spider_output
    for i in result:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 338, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\core\spidermw.py", line 64, in _evaluate_iterable
    for r in iterable:
  File "D:\anacoda\envs\py37\lib\site-packages\scrapy\spiders\crawl.py", line 116, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\spiders\BaiduHotspot.py", line 21, in parse_item_baidu
    assert re.match(r"http://baijiahao.baidu.com/s\?id=\w+", string=response.url) is not None
AssertionError
2020-06-30 19:59:05 [scrapy.core.engine] INFO: Closing spider (finished)
2020-06-30 19:59:05 [scrapy.core.engine] ERROR: Scraper close failure
Traceback (most recent call last):
  File "D:\anacoda\envs\py37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\study\Sophomore\Semester2\大型程序设计\github\news_hotspot_crawler\hotspot_crawler\pipelines.py", line 35, in close_spider
    MysqlOperation.dis_connect()
TypeError: dis_connect() missing 1 required positional argument: 'self'
2020-06-30 19:59:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 55664,
 'downloader/request_count': 155,
 'downloader/request_method_count/GET': 155,
 'downloader/response_bytes': 1249381,
 'downloader/response_count': 155,
 'downloader/response_status_count/200': 141,
 'downloader/response_status_count/302': 14,
 'dupefilter/filtered': 33,
 'elapsed_time_seconds': 37.309999,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 6, 30, 11, 59, 5, 153018),
 'item_scraped_count': 21,
 'log_count/DEBUG': 177,
 'log_count/ERROR': 120,
 'log_count/INFO': 12,
 'request_depth_max': 2,
 'response_received_count': 141,
 'scheduler/dequeued': 155,
 'scheduler/dequeued/memory': 155,
 'scheduler/enqueued': 155,
 'scheduler/enqueued/memory': 155,
 'spider_exceptions/AssertionError': 119,
 'start_time': datetime.datetime(2020, 6, 30, 11, 58, 27, 843019)}
2020-06-30 19:59:05 [scrapy.core.engine] INFO: Spider closed (finished)
